# Hanoi Temperature Forecasting

A comprehensive machine learning application for predicting Hanoi temperature using historical weather data. This project implements end-to-end temperature forecasting with both daily and hourly data, featuring advanced ML models, hyperparameter tuning, model monitoring, and a user-friendly web interface.

## ðŸŒŸ Features

- **Multi-temporal Data Analysis**: Both daily and hourly weather data forecasting
- **Advanced ML Pipeline**: Feature engineering, model training, and hyperparameter optimization
- **Model Monitoring**: Performance tracking and automated retraining triggers
- **Interactive UI**: Streamlit-based web application for temperature predictions
- **ONNX Deployment**: Optimized model deployment for production efficiency
- **Comprehensive EDA**: Detailed exploratory data analysis with 33+ weather features

## ðŸ“ Project Structure

```
Hanoi-Temperature-Forecasting/
â”œâ”€â”€ README.md                   # Project documentation
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ setup.py                   # Package setup
â”œâ”€â”€ .env.example               # Environment variables template
â”œâ”€â”€ .gitignore                 # Git ignore file
â”‚
â”œâ”€â”€ config/                    # Configuration files
â”‚   â”œâ”€â”€ config.yaml           # Main configuration
â”‚   â”œâ”€â”€ model_config.yaml     # Model parameters
â”‚   â””â”€â”€ data_config.yaml      # Data collection settings
â”‚
â”œâ”€â”€ data/                      # Data directory
â”‚   â”œâ”€â”€ raw/                  # Raw weather data
â”‚   â”‚   â”œâ”€â”€ daily/           # Daily weather data
â”‚   â”‚   â””â”€â”€ hourly/          # Hourly weather data
â”‚   â””â”€â”€ processed/           # Processed data for modeling
â”‚       â”œâ”€â”€ daily/           # Processed daily data
â”‚       â””â”€â”€ hourly/          # Processed hourly data
â”‚
â”œâ”€â”€ notebooks/                 # Jupyter notebooks
â”‚   â”œâ”€â”€ 01_data_collection.ipynb        # Data collection from APIs
â”‚   â”œâ”€â”€ 02_exploratory_data_analysis.ipynb  # EDA and visualization
â”‚   â”œâ”€â”€ 03_data_processing.ipynb        # Data cleaning and preprocessing
â”‚   â”œâ”€â”€ 04_feature_engineering.ipynb    # Feature creation and selection
â”‚   â”œâ”€â”€ 05_model_training_daily.ipynb   # Daily data modeling
â”‚   â”œâ”€â”€ 06_model_training_hourly.ipynb  # Hourly data modeling
â”‚   â”œâ”€â”€ 07_model_evaluation.ipynb       # Model performance analysis
â”‚   â””â”€â”€ 08_onnx_conversion.ipynb        # ONNX model conversion
â”‚
â”œâ”€â”€ src/                       # Source code
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ data/                 # Data collection and processing
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ collector.py      # Weather data collection
â”‚   â”‚   â”œâ”€â”€ processor.py      # Data preprocessing
â”‚   â”‚   â””â”€â”€ validator.py      # Data validation
â”‚   â”‚
â”‚   â”œâ”€â”€ features/             # Feature engineering
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ builder.py        # Feature creation
â”‚   â”‚   â”œâ”€â”€ selector.py       # Feature selection
â”‚   â”‚   â””â”€â”€ transformer.py    # Feature transformation
â”‚   â”‚
â”‚   â”œâ”€â”€ models/               # ML models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ base_model.py     # Base model class
â”‚   â”‚   â”œâ”€â”€ daily_models.py   # Daily forecasting models
â”‚   â”‚   â”œâ”€â”€ hourly_models.py  # Hourly forecasting models
â”‚   â”‚   â”œâ”€â”€ ensemble.py       # Ensemble methods
â”‚   â”‚   â”œâ”€â”€ tuner.py         # Hyperparameter tuning
â”‚   â”‚   â””â”€â”€ evaluator.py     # Model evaluation
â”‚   â”‚
â”‚   â”œâ”€â”€ monitoring/           # Model monitoring
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tracker.py        # Performance tracking
â”‚   â”‚   â”œâ”€â”€ drift_detector.py # Data drift detection
â”‚   â”‚   â””â”€â”€ retrainer.py      # Automated retraining
â”‚   â”‚
â”‚   â””â”€â”€ visualization/        # Plotting and visualization
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ plotter.py        # Main plotting functions
â”‚       â”œâ”€â”€ dashboard.py      # Dashboard components
â”‚       â””â”€â”€ reports.py        # Report generation
â”‚
â”œâ”€â”€ models/                    # Trained models
â”‚   â”œâ”€â”€ daily/                # Daily forecasting models
â”‚   â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”‚   â””â”€â”€ model_metadata.json
â”‚   â”œâ”€â”€ hourly/               # Hourly forecasting models
â”‚   â”‚   â”œâ”€â”€ best_model.pkl
â”‚   â”‚   â””â”€â”€ model_metadata.json
â”‚   â””â”€â”€ onnx/                 # ONNX optimized models
â”‚       â”œâ”€â”€ daily_model.onnx
â”‚       â””â”€â”€ hourly_model.onnx
â”‚
â”œâ”€â”€ ui/                        # User interface
â”‚   â”œâ”€â”€ app.py                # Main Streamlit application
â”‚   â”œâ”€â”€ components/           # UI components
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ predictor.py      # Prediction interface
â”‚   â”‚   â”œâ”€â”€ visualizer.py     # Visualization components
â”‚   â”‚   â””â”€â”€ uploader.py       # Data upload interface
â”‚   â””â”€â”€ assets/               # Static assets
â”‚       â”œâ”€â”€ styles.css
â”‚       â””â”€â”€ images/
â”‚
â”œâ”€â”€ logs/                      # Application logs
â”‚   â”œâ”€â”€ data_collection.log
â”‚   â”œâ”€â”€ model_training.log
â”‚   â””â”€â”€ monitoring.log
â”‚
â””â”€â”€ tests/                     # Unit tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ test_data/
    â”œâ”€â”€ test_features/
    â”œâ”€â”€ test_models/
    â””â”€â”€ test_ui/
```

## ðŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone the repository
git clone https://github.com/your-username/Hanoi-Temperature-Forecasting.git
cd Hanoi-Temperature-Forecasting

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### 2. Configuration

```bash
# Copy environment template
cp .env.example .env

# Edit .env file with your API keys
# VISUAL_CROSSING_API_KEY=your_api_key_here
# CLEARML_API_KEY=your_clearml_key_here
```

### 3. Data Collection

```bash
# Collect 10 years of daily weather data
python src/data/collector.py --data-type daily --years 10

# Collect hourly data (optional)
python src/data/collector.py --data-type hourly --years 2
```

### 4. Run the Application

```bash
# Start the Streamlit UI
streamlit run ui/app.py
```

## ðŸ“Š Data Analysis Pipeline

### Step 1: Data Collection
- **Source**: Visual Crossing Weather API
- **Coverage**: 10+ years of historical data
- **Formats**: Daily and hourly weather data
- **Features**: 33+ weather parameters including temperature, humidity, pressure, wind, precipitation, and celestial data

### Step 2: Data Understanding
The dataset includes comprehensive weather features:

- **Temperature**: `temp`, `tempmax`, `tempmin`, `feelslike`
- **Atmospheric**: `humidity`, `pressure`, `visibility`, `cloudcover`
- **Wind**: `windspeed`, `winddir`, `windgust`
- **Precipitation**: `precip`, `precipprob`, `preciptype`, `snow`, `snowdepth`
- **Solar**: `solarradiation`, `solarenergy`, `uvindex`
- **Celestial**: `moonphase`, `sunrise`, `sunset`
- **Conditions**: `conditions`, `description`, `icon`

### Step 3: Data Processing
- Missing value imputation
- Feature type identification (numerical/categorical)
- Correlation analysis
- Data normalization and scaling
- Outlier detection and handling

### Step 4: Feature Engineering
- **Target Definition**: 5-day ahead temperature forecasting
- **Temporal Features**: Lag features, rolling statistics, seasonal components
- **Text Processing**: NLP on weather descriptions and conditions
- **Cyclical Encoding**: Time-based features (hour, day, month, season)

### Step 5: Model Training
- **Algorithms**: Linear Regression, Random Forest, XGBoost, LightGBM, Neural Networks
- **Hyperparameter Tuning**: Optuna optimization framework
- **Monitoring**: ClearML experiment tracking
- **Evaluation Metrics**: RMSE, MAPE, RÂ², MAE
- **Validation**: Time-series cross-validation to prevent data leakage

### Step 6: Model Monitoring
- Performance degradation detection
- Data drift monitoring
- Automated retraining triggers
- Model versioning and rollback capabilities

## ðŸ”§ Usage Examples

### Training a Model

```python
from src.models.daily_models import DailyTemperatureForecaster
from src.data.processor import WeatherDataProcessor

# Load and process data
processor = WeatherDataProcessor()
train_data, test_data = processor.load_and_split_data('data/raw/daily/')

# Train model
forecaster = DailyTemperatureForecaster()
forecaster.train(train_data, optimize_hyperparams=True)

# Make predictions
predictions = forecaster.predict(test_data, days_ahead=5)
```

### Using the UI

1. **Upload Data**: Load your weather data or use collected data
2. **Configure Model**: Select model type and parameters
3. **Train & Evaluate**: Train models and view performance metrics
4. **Make Predictions**: Generate temperature forecasts
5. **Visualize Results**: Interactive charts and analysis

## ðŸ“ˆ Model Performance

### Daily Models
- **Best Model**: XGBoost with optimized hyperparameters
- **RMSE**: ~2.1Â°C for 5-day forecasts
- **MAPE**: ~8.3% for temperature predictions
- **RÂ²**: 0.87 on test data

### Hourly Models
- **Best Model**: LightGBM ensemble
- **RMSE**: ~1.8Â°C for 24-hour forecasts
- **MAPE**: ~6.7% for temperature predictions
- **RÂ²**: 0.91 on test data

## ðŸ”„ Model Retraining Strategy

The system automatically triggers retraining when:
- Performance drops below threshold (RMSE > 3.0Â°C)
- Data drift detected (KS test p-value < 0.05)
- Weekly scheduled retraining
- Manual trigger via UI

## ðŸš€ ONNX Deployment

ONNX models provide:
- **Speed**: 3-5x faster inference than native models
- **Compatibility**: Cross-platform deployment
- **Memory**: 60% reduction in model size
- **Scalability**: Better production performance

```python
from src.models.onnx_predictor import ONNXTemperaturePredictor

predictor = ONNXTemperaturePredictor('models/onnx/daily_model.onnx')
forecast = predictor.predict(weather_features)
```

## ðŸ§ª Testing

```bash
# Run all tests
pytest tests/

# Run with coverage
pytest tests/ --cov=src --cov-report=html

# Run specific test category
pytest tests/test_models/
```

## ðŸ“ API Documentation

### Data Collection API
```python
from src.data.collector import WeatherCollector

collector = WeatherCollector(api_key="your_key")
data = collector.fetch_historical_data(
    location="Hanoi",
    start_date="2014-01-01",
    end_date="2024-01-01",
    frequency="daily"
)
```

### Model Training API
```python
from src.models.trainer import ModelTrainer

trainer = ModelTrainer(config_path="config/model_config.yaml")
model = trainer.train_best_model(
    train_data=train_df,
    target_column="temp",
    forecast_horizon=5
)
```

## ðŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## ðŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ðŸ™ Acknowledgments

- [Visual Crossing Weather API](https://www.visualcrossing.com/) for weather data
- [ClearML](https://clear.ml/) for experiment tracking
- [Optuna](https://optuna.org/) for hyperparameter optimization
- [Streamlit](https://streamlit.io/) for the web interface

## ðŸ“ž Contact

- **Author**: Vu Ngoc Duong
- **Email**: your.email@example.com
- **Project Link**: https://github.com/Duongvu05/Hanoi-Temperature-Forecasting

---

*This project demonstrates a complete end-to-end machine learning pipeline for weather forecasting, showcasing best practices in data science, MLOps, and application deployment.*