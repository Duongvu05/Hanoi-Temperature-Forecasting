{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d746e576",
   "metadata": {},
   "source": [
    "# Hanoi Temperature Forecasting - Machine Learning Pipeline\n",
    "\n",
    "Clean and modular implementation of sliding window time series forecasting with multiple ML algorithms.\n",
    "\n",
    "## Pipeline Overview\n",
    "1. **Data Loading & Preprocessing**\n",
    "2. **Sliding Window Creation**\n",
    "3. **Model Training & Evaluation** \n",
    "4. **Results Visualization**\n",
    "5. **Model Persistence**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cccb1fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add project root to path\n",
    "project_root = '/home/vungocduong/Hanoi-Temperature-Forecasting'\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import custom modules\n",
    "from src.data.sliding_window import TimeSeriesWindowProcessor\n",
    "from src.models.ml_trainer import MLModelTrainer\n",
    "from src.visualization.model_plots import ModelVisualizer\n",
    "\n",
    "print(\"‚úÖ All modules imported successfully!\")\n",
    "print(f\"üìÅ Project root: {project_root}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8bf821",
   "metadata": {},
   "source": [
    "## 1. Data Loading & Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c478f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess data\n",
    "data_path = f'{project_root}/data/raw/daily/Daily_Data.csv'\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "print(f\"Raw data shape: {df.shape}\")\n",
    "print(f\"Columns: {list(df.columns)}\")\n",
    "\n",
    "# Select only numeric features\n",
    "df_features = df.select_dtypes(include=[np.number])\n",
    "print(f\"\\nNumeric features shape: {df_features.shape}\")\n",
    "print(f\"Numeric columns ({len(df_features.columns)}):\")\n",
    "for i, col in enumerate(df_features.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022bbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle missing values\n",
    "print(\"=\"*60)\n",
    "print(\"CHECKING & HANDLING NaN VALUES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "nan_counts = df_features.isnull().sum()\n",
    "nan_columns = nan_counts[nan_counts > 0]\n",
    "\n",
    "if len(nan_columns) > 0:\n",
    "    print(f\"\\nFound {len(nan_columns)} columns with NaN values:\")\n",
    "    for col, count in nan_columns.items():\n",
    "        percentage = (count / len(df_features)) * 100\n",
    "        print(f\"  ‚Ä¢ {col:20s}: {count:5d} NaN ({percentage:6.2f}%)\")\n",
    "    \n",
    "    # Fill NaN with column mean\n",
    "    print(\"\\nFilling NaN values with column means...\")\n",
    "    for col in nan_columns.index:\n",
    "        col_mean = df_features[col].mean()\n",
    "        df_features[col].fillna(col_mean, inplace=True)\n",
    "        print(f\"  ‚úÖ {col}: Filled with mean = {col_mean:.4f}\")\n",
    "    \n",
    "    # Verify no NaN remains\n",
    "    remaining_nan = df_features.isnull().sum().sum()\n",
    "    print(f\"\\n‚úÖ Remaining NaN after processing: {remaining_nan}\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ No NaN values found!\")\n",
    "\n",
    "# Final verification\n",
    "assert df_features.isnull().sum().sum() == 0, \"ERROR: NaN values still exist!\"\n",
    "print(f\"\\nüìä Final dataset: {df_features.shape} (100% valid data)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc56e09",
   "metadata": {},
   "source": [
    "## 2. Train-Test Split & Sliding Windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0198b43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "train_ratio = 0.8\n",
    "train_index = int(len(df_features) * train_ratio)\n",
    "\n",
    "print(f\"Dataset split ({train_ratio:.0%}-{1-train_ratio:.0%}):\")\n",
    "print(f\"  ‚Ä¢ Train: 0 to {train_index-1} ({train_index:,} samples)\")\n",
    "print(f\"  ‚Ä¢ Test:  {train_index} to {len(df_features)-1} ({len(df_features) - train_index:,} samples)\")\n",
    "\n",
    "# Get temperature column index\n",
    "temp_col_idx = list(df_features.columns).index('temp')\n",
    "print(f\"  ‚Ä¢ Temperature column index: {temp_col_idx}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db6ff570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize sliding window processor\n",
    "window_processor = TimeSeriesWindowProcessor(\n",
    "    window_length=25,\n",
    "    forecast_horizon=[1, 2, 3, 4, 5],\n",
    "    step_length=5\n",
    ")\n",
    "\n",
    "print(\"Sliding Window Configuration:\")\n",
    "print(f\"  ‚Ä¢ Window length: {window_processor.window_length} timesteps\")\n",
    "print(f\"  ‚Ä¢ Forecast horizon: {window_processor.forecast_horizon} timesteps\")\n",
    "print(f\"  ‚Ä¢ Step length: {window_processor.step_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef1d66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training windows\n",
    "train_indices = np.arange(train_index)\n",
    "train_windows = window_processor.create_windows(train_indices)\n",
    "\n",
    "print(f\"\\nTraining windows: {len(train_windows)}\")\n",
    "print(\"First 3 windows:\")\n",
    "for i, (train_idx, test_idx) in enumerate(train_windows[:3]):\n",
    "    print(f\"  Window {i}: Train=[{train_idx[0]}:{train_idx[-1]}], Test={test_idx.tolist()}\")\n",
    "\n",
    "# Process training windows\n",
    "print(\"\\nProcessing training windows...\")\n",
    "processed_train_windows = window_processor.process_windows(\n",
    "    df_features, train_windows, validate_no_nan=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Processed {len(processed_train_windows)} training windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef98160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create test windows\n",
    "test_indices = np.arange(train_index, len(df_features))\n",
    "test_windows = window_processor.create_windows(test_indices)\n",
    "\n",
    "print(f\"Test windows: {len(test_windows)}\")\n",
    "\n",
    "# Process test windows\n",
    "print(\"Processing test windows...\")\n",
    "processed_test_windows = window_processor.process_windows(\n",
    "    df_features, test_windows, validate_no_nan=True\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Processed {len(processed_test_windows)} test windows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0df6ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert windows to training arrays\n",
    "X_train, y_train = window_processor.windows_to_arrays(processed_train_windows)\n",
    "X_test, y_test = window_processor.windows_to_arrays(processed_test_windows)\n",
    "\n",
    "print(f\"Training arrays:\")\n",
    "print(f\"  ‚Ä¢ X_train: {X_train.shape} (windows, timesteps, features)\")\n",
    "print(f\"  ‚Ä¢ y_train: {y_train.shape} (windows, forecast_steps, features)\")\n",
    "\n",
    "print(f\"\\nTest arrays:\")\n",
    "print(f\"  ‚Ä¢ X_test: {X_test.shape}\")\n",
    "print(f\"  ‚Ä¢ y_test: {y_test.shape}\")\n",
    "\n",
    "# Verify no NaN\n",
    "arrays_to_check = [('X_train', X_train), ('y_train', y_train), ('X_test', X_test), ('y_test', y_test)]\n",
    "for name, arr in arrays_to_check:\n",
    "    has_nan = np.isnan(arr).any()\n",
    "    print(f\"  ‚Ä¢ {name} has NaN: {has_nan}\")\n",
    "    assert not has_nan, f\"{name} contains NaN values!\"\n",
    "\n",
    "print(\"\\n‚úÖ All arrays verified - NO NaN values!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f9688",
   "metadata": {},
   "source": [
    "## 3. Machine Learning Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c5326d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ML trainer\n",
    "ml_trainer = MLModelTrainer()\n",
    "\n",
    "# Prepare data for ML models\n",
    "X_train_flat, y_train_target, X_test_flat, y_test_target = ml_trainer.prepare_data(\n",
    "    X_train, y_train, X_test, y_test, temp_col_idx\n",
    ")\n",
    "\n",
    "print(f\"Prepared data for ML models:\")\n",
    "print(f\"  ‚Ä¢ X_train_flat: {X_train_flat.shape} (windows, flattened_features)\")\n",
    "print(f\"  ‚Ä¢ y_train_target: {y_train_target.shape} (windows, avg_forecast)\")\n",
    "print(f\"  ‚Ä¢ X_test_flat: {X_test_flat.shape}\")\n",
    "print(f\"  ‚Ä¢ y_test_target: {y_test_target.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750978d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all ML models\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING MACHINE LEARNING MODELS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = ml_trainer.train_all_models(\n",
    "    X_train_flat, y_train_target, X_test_flat, y_test_target\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Trained {len(results)} models successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1505c613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model comparison\n",
    "comparison_df = ml_trainer.get_comparison_dataframe()\n",
    "best_model_name, best_model = ml_trainer.get_best_model()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON (Sorted by Test RMSE)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nüèÜ BEST MODEL: {best_model_name}\")\n",
    "best_row = comparison_df.iloc[0]\n",
    "print(f\"  ‚Ä¢ Test RMSE: {best_row['Test RMSE']:.6f}\")\n",
    "print(f\"  ‚Ä¢ Test MAE:  {best_row['Test MAE']:.6f}\")\n",
    "print(f\"  ‚Ä¢ Test R¬≤:   {best_row['Test R¬≤']:.4f}\")\n",
    "print(f\"  ‚Ä¢ Test MAPE: {best_row['Test MAPE (%)']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d0fc3",
   "metadata": {},
   "source": [
    "## 4. Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ccf899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize visualizer\n",
    "visualizer = ModelVisualizer()\n",
    "\n",
    "# Create model comparison plots\n",
    "fig, axes = visualizer.plot_model_comparison(comparison_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1f6adb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot best model predictions\n",
    "best_predictions = results[best_model_name]['y_pred']\n",
    "fig, axes = visualizer.plot_predictions_comparison(\n",
    "    y_test_target, best_predictions, best_model_name\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3db9c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models predictions\n",
    "fig, axes = visualizer.plot_all_models_comparison(\n",
    "    results, y_test_target, num_samples=100\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b6214",
   "metadata": {},
   "source": [
    "## 5. Model Persistence & Results Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69406c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "models_dir = f'{project_root}/models/daily'\n",
    "processed_dir = f'{project_root}/data/processed'\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(models_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Save models\n",
    "ml_trainer.save_models(models_dir)\n",
    "\n",
    "# Save results\n",
    "results_path = f'{processed_dir}/ml_results.pkl'\n",
    "comparison_csv_path = f'{processed_dir}/ml_models_comparison.csv'\n",
    "ml_trainer.save_results(results_path, comparison_csv_path)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ ALL MODELS AND RESULTS SAVED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"üìÅ Models directory: {models_dir}\")\n",
    "print(f\"üìÅ Results file: {results_path}\")\n",
    "print(f\"üìÅ Comparison CSV: {comparison_csv_path}\")\n",
    "print(f\"üèÜ Best model: {best_model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd4722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up\n",
    "visualizer.close_all()\n",
    "print(\"‚úÖ Pipeline completed successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
