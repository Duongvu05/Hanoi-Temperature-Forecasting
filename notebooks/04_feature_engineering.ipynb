{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3db127e",
   "metadata": {},
   "source": [
    "## 4. Feature_Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a308cc12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”§ FEATURE ENGINEERING SETUP\n",
      "===================================\n",
      "âœ… Libraries imported successfully!\n",
      "ðŸ“Š Pandas version: 2.2.3\n",
      "ðŸ¤– Scikit-learn available for feature selection\n"
     ]
    }
   ],
   "source": [
    "#Import libraries for feature engineering\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.feature_selection import mutual_info_regression, SelectKBest\n",
    "import warnings\n",
    "\n",
    "# Configure settings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "print(\"ðŸ”§ FEATURE ENGINEERING SETUP\")\n",
    "print(\"=\" * 35)\n",
    "print(\"âœ… Libraries imported successfully!\")\n",
    "print(f\"ðŸ“Š Pandas version: {pd.__version__}\")\n",
    "print(f\"ðŸ¤– Scikit-learn available for feature selection\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28cc0b9d",
   "metadata": {},
   "source": [
    "Imports and setup  \n",
    "    - Import libraries (pandas, numpy, matplotlib, seaborn, sklearn helpers).  \n",
    "    - Configure warnings and pandas display.  \n",
    "    - Print simple environment/info messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "42abe518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load cleaned data (from data processing step)\n",
    "df = pd.read_csv('../data/processed/prepocessed_daily_data.csv')  # Will be updated to use processed data\n",
    "df.set_index('datetime', inplace=True)\n",
    "df.index = pd.to_datetime(df.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77eb5b",
   "metadata": {},
   "source": [
    "Load cleaned data  \n",
    "    - Read processed CSV into `df`.  \n",
    "    - Set `datetime` as index and convert to pandas datetime index."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7e31b5",
   "metadata": {},
   "source": [
    "Inspect columns  \n",
    "    - Quick evaluation of `df.columns` to review available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "04245510",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sunrise'] = pd.to_datetime(df['sunrise'])\n",
    "df['sunset'] = pd.to_datetime(df['sunset'])\n",
    "df['day_length_hours'] = df['sunset'] - df['sunrise']\n",
    "df = df.drop(columns=['sunrise', 'sunset'])\n",
    "df['day_length_hours'] = df['day_length_hours'].dt.total_seconds() / 3600.0\n",
    "\n",
    "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
    "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
    "df['dayofyear_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
    "df['dayofyear_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
    "\n",
    "df.drop(columns=['day', 'month', 'day_of_year', 'conditions'], inplace=True)\n",
    "\n",
    "df['target5+'] = df['temp'].shift(-5)\n",
    "df['target4+'] = df['temp'].shift(-4)\n",
    "df['target3+'] = df['temp'].shift(-3)\n",
    "df['target2+'] = df['temp'].shift(-2)\n",
    "df['target1+'] = df['temp'].shift(-1)\n",
    "df = df[~df['target5+'].isna()].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bc517a",
   "metadata": {},
   "source": [
    "Time features and forecast targets  \n",
    "    - Convert `sunrise`/`sunset` to datetime and compute `day_length_hours`; drop original columns.  \n",
    "    - Create cyclical encodings: `month_sin`, `month_cos`, `dayofyear_sin`, `dayofyear_cos`.  \n",
    "    - Drop original `day`, `month`, `day_of_year`.  \n",
    "    - Create shifted forecast targets: `target1+` â€¦ `target5+` (future temperature at 1â€“5 steps).  \n",
    "    - Drop rows with NaN introduced by the furthest shift (`target5+`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b61955ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"temp_solar_interaction\"] = df[\"temp\"] * df[\"solarradiation\"]\n",
    "df[\"uv_temp_interaction\"] = df[\"uvindex\"] * df[\"temp\"]\n",
    "df['temp_cloudcover_interaction'] = df['temp'] * df['cloudcover']\n",
    "df['temp_sealevelpressure_interaction'] = df['temp'] * df['sealevelpressure']\n",
    "df['weighted_precip'] = df['precipprob'] * df['precip']\n",
    "df['effective_solar'] = df['solarradiation'] * (1 - df['cloudcover']/100)\n",
    "df['precip_impact'] = df['precipprob'] * df['precip']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f8e1de",
   "metadata": {},
   "source": [
    "Interaction features and domain transforms  \n",
    "    - New features combining sensors: `temp_solar_interaction`, `uv_temp_interaction`, `temp_cloudcover_interaction`, `temp_sealevelpressure_interaction`.  \n",
    "    - Weighted precipitation and effective solar radiation: `weighted_precip`, `effective_solar`, `precip_impact`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "35d88bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['wind_u'] = df['windspeed'] * np.cos(2 * np.pi * df['winddir'] / 360)  # giÃ³ Ä‘Ã´ng-tÃ¢y\n",
    "df['wind_v'] = df['windspeed'] * np.sin(2 * np.pi * df['winddir'] / 360)  # giÃ³ nam-báº¯c\n",
    "df = df.drop('winddir', axis=1)\n",
    "\n",
    "df['temp_minus_dew'] = df['temp'] - df['dew']\n",
    "\n",
    "# Táº¡o feature moonphase_sin\n",
    "df['moonphase_sin'] = np.sin(2 * np.pi * df['moonphase'] / 1)\n",
    "\n",
    "# Táº¡o feature moonphase_cos\n",
    "df['moonphase_cos'] = np.cos(2 * np.pi * df['moonphase'] / 1)\n",
    "\n",
    "# (TÃ¹y chá»n) Bá» cá»™t moonphase gá»‘c\n",
    "df = df.drop('moonphase', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f28d7a8",
   "metadata": {},
   "source": [
    "Wind decomposition and moonphase  \n",
    "    - Convert polar wind (`windspeed`, `winddir`) to Cartesian components: `wind_u`, `wind_v`; drop `winddir`.  \n",
    "    - Compute moonphase cyclical features: `moonphase_sin`, `moonphase_cos` and drop original `moonphase`.  \n",
    "    - Note: `temp_minus_dew` is computed in the cell but not saved back to `df` (might be intentional or an oversight)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1be2959d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lagging features\n",
    "def create_lag_features(df, cols, lags):\n",
    "    for col in cols:\n",
    "        for lag in lags:\n",
    "            df[f\"{col}_lag_{lag}\"] = df[col].shift(lag)\n",
    "    return df\n",
    "\n",
    "# Specify columns and lags\n",
    "# Get all numerical columns\n",
    "computing_columns = df.drop(columns=['year', 'season', 'target5+', 'target4+', 'target3+', 'target2+', 'target1+', 'month_sin',\n",
    "                                    'month_cos', 'dayofyear_sin', 'dayofyear_cos']).columns\n",
    "\n",
    "lag_steps = [1, 2, 3, 5, 7, 10, 14, 21, 30]  # Example lag steps\n",
    "\n",
    "# Apply lagging features before handling rolling horizons\n",
    "df = create_lag_features(df, computing_columns, lag_steps)\n",
    "\n",
    "# Function to compute rolling mean and percentage change\n",
    "def compute_rolling(df, horizon, col):\n",
    "    label = f\"rolling_{horizon}_{col}\"\n",
    "    df[label] = df[col].rolling(horizon, min_periods=horizon).mean()  # Ensure full horizon is used\n",
    "    df[f\"{label}_change\"] = df[col] - df[label]\n",
    "    return df\n",
    "\n",
    "# Compute rolling features for specified horizons\n",
    "rolling_horizons = [3, 4, 5, 7, 14, 21, 30]  # Rolling windows of 3, 7, 14 days\n",
    "for horizon in rolling_horizons:\n",
    "    for col in computing_columns:\n",
    "        df = compute_rolling(df, horizon, col)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "910afa89",
   "metadata": {},
   "source": [
    "Lag and rolling mean features  \n",
    "    - Define `create_lag_features()` and produce lag features for selected numerical columns using lags [1,2,3,5,7,10,14,21,30].  \n",
    "    - Define `compute_rolling()` to compute rolling means and difference to current value.  \n",
    "    - Apply rolling windows for horizons [3,7,14,21,30] for the same set of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "be9aa3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Months and days average\n",
    "def expand_mean(df):\n",
    "    return df.expanding(1).mean()\n",
    "\n",
    "for col in computing_columns:\n",
    "    df[f\"month_avg_{col}\"] = df[col].groupby(df.index.month, group_keys=False).apply(expand_mean)\n",
    "    df[f\"day_avg_{col}\"] = df[col].groupby(df.index.day_of_year, group_keys=False).apply(expand_mean)\n",
    "    df[f\"year_avg_{col}\"] = df[col].groupby(df.index.year, group_keys=False).apply(expand_mean)\n",
    "    df[f\"season_avg_{col}\"] = df[col].groupby(df['season'], group_keys=False).apply(expand_mean)\n",
    "    df[\"day_max_temp\"] = df['temp'].groupby(df.index.day_of_year, group_keys=False).cummax()\n",
    "    df[\"day_min_temp\"] = df['temp'].groupby(df.index.day_of_year, group_keys=False).cummin()\n",
    "\n",
    "df[\"temp_anomaly_vs_month_avg\"] = df[\"temp\"] - df[\"month_avg_temp\"]\n",
    "df[\"temp_anomaly_vs_day_avg\"] = df[\"temp\"] - df[\"day_avg_temp\"]\n",
    "df[\"temp_anomaly_vs_season_avg\"] = df[\"temp\"] - df[\"season_avg_temp\"]\n",
    "\n",
    "df[\"pressure_trend_2d\"] = df[\"sealevelpressure\"].diff(2)\n",
    "df[\"pressure_trend_3d\"] = df[\"sealevelpressure\"].diff(3)\n",
    "df[\"pressure_trend_5d\"] = df[\"sealevelpressure\"].diff(5)\n",
    "df[\"pressure_trend_7d\"] = df[\"sealevelpressure\"].diff(7)\n",
    "df[\"pressure_trend_14d\"] = df[\"sealevelpressure\"].diff(14)\n",
    "df[\"pressure_trend_21d\"] = df[\"sealevelpressure\"].diff(21)\n",
    "df[\"pressure_trend_30d\"] = df[\"sealevelpressure\"].diff(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57985178",
   "metadata": {},
   "source": [
    "Expanding/grouped aggregates and volatility  \n",
    "    - Compute expanding (cumulative) means grouped by month, day-of-year, year, and season (e.g., `month_avg_*`, `day_avg_*`, `year_avg_*`, `season_avg_*`).  \n",
    "    - Add monthly max/min temperature trackers and temperature volatility (rolling std for 7,14,21,30).  \n",
    "    - Flags and anomalies: `temp_spike_flag`, `temp_anomaly_vs_month_avg`, `temp_anomaly_vs_season_avg`.  \n",
    "    - Pressure trend features: `pressure_trend_3d` and `pressure_trend_7d` (note: code uses shift(30) for the 7d variable â€” verify intended window)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75ca7b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of NaN values in each column after handling rolling horizons and lagging:\n",
      "Series([], dtype: int64)\n",
      "\n",
      "The dataframe does not contain any NaN values.\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with NaN values caused by rolling horizons\n",
    "df = df.iloc[30:]\n",
    "# Verify no NaN values exist\n",
    "nan_summary = df.isna().sum()\n",
    "print(\"Summary of NaN values in each column after handling rolling horizons and lagging:\")\n",
    "print(nan_summary[nan_summary > 0].sort_values())\n",
    "\n",
    "if df.isna().any().any():\n",
    "    print(\"\\nThe dataframe contains NaN values.\")\n",
    "else:\n",
    "    print(\"\\nThe dataframe does not contain any NaN values.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc4ffa",
   "metadata": {},
   "source": [
    "Clean-up and NaN handling  \n",
    "    - Drop the first 30 rows to remove rows affected by rolling windows and lags.  \n",
    "    - Print a summary of remaining NaNs and confirm whether the DataFrame contains NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ef6fec4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3619, 947)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43ce2bc9",
   "metadata": {},
   "source": [
    " Shape check  \n",
    "    - Print `df.shape` to inspect final dataset dimensions after feature engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "460ecb2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/processed/feature_engineering_daily_data2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010effc9",
   "metadata": {},
   "source": [
    "Persist features  \n",
    "    - Save the final engineered DataFrame to CSV: `feature_engineering_daily_data2.csv`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0118a82e",
   "metadata": {},
   "source": [
    "## Engineered Features Overview\n",
    "\n",
    "This section documents only some key the engineered features used by the daily forecasting pipeline. It excludes raw/base inputs and focuses on what was created during feature engineering.\n",
    "\n",
    "| Variable Group | Variable Name | Definition | Effect on Model |\n",
    "|---|---|---|---|\n",
    "| Cyclical Features | `sin_doy`, `cos_doy` | Sine and cosine encodings of day-of-year to preserve annual cyclicality | Provides smooth seasonal patterning; anchors warm/cool seasons without month boundary jumps |\n",
    "| Day Length | `day_length_hours` | Number of daylight hours for the date/location | Longer days typically raise daytime temps and expand diurnal range (positive, season-dependent) |\n",
    "| Day Length (lags) | `day_length_hours_lag_21`, `day_length_hours_lag_30` | Day length 21/30 days earlier (seasonal memory) | Mild positive in warming seasons; captures delayed seasonal effects |\n",
    "| Temperature lags | `temp_lag_1`, `temp_lag_7`, `temp_lag_30` | Temperature 1/7/30 days earlier | Strong positive autocorrelation for near horizons; `lag_30` reflects seasonal baseline |\n",
    "| Moving averages (rolling) | `rolling_3_*`, `rolling_7_*`, `rolling_30_*` | Rolling means/STD of meteorological signals (e.g., `rolling_30_sealevelpressure`) | Noise reduction and regime identification; longer windows capture persistent patterns |\n",
    "| Trend / Change | `*_trend_7`, `*_change_3`, `rolling_3_sealevelpressure_change` | 7â€‘day linear trend or 3â€‘day deltas | Pressure drops often precede cooling/fronts; rising pressure stabilizes temperatures |\n",
    "| Interactions | `temp_sealevelpressure_interaction` | Firstâ€‘order interaction of temperature Ã— seaâ€‘level pressure | Captures stabilityâ€“heating synergy; sign depends on regime and cloudiness |\n",
    "| Wind components | `wind_u`, `wind_v` | Decomposition of wind into zonal (`u`, eastâ€“west) and meridional (`v`, northâ€“south) components | Directional advection of warm/cold air; effect depends on local climatology and fetch |\n",
    "| Month (categorical) | `month` (or oneâ€‘hot) | Calendar month to encode discrete seasonal regimes | Positions forecast within monthly regime shifts; complements cyclical encoding |\n",
    "| Priorâ€‘day aggregates | `day_avg_feelslike`, `day_avg_tempmin`, `day_avg_tempmax` | Previous dayâ€™s average/min/max | Provides shortâ€‘term thermal context; generally positive for nextâ€‘day levels |\n",
    "| Temperature anomaly | `temp_minus_season_avg` (aka `temp_anomaly`) | Deviation from climatological/seasonal average | Positive anomaly â†’ forecast above seasonal baseline; negative â†’ below |\n",
    "| Seasonal pressure baseline | `season_avg_sealevelpressure` | Seasonal average of seaâ€‘level pressure | Regime indicator; interacts with temperature response and cloud cover |\n",
    "\n",
    "Notes\n",
    "- Directions are indicative; confirm with SHAP/Permutation Importance on your latest data slice.\n",
    "- Drift watchlist (recently flagged with high PSI/KS): `day_length_hours_lag_21`, `day_length_hours_lag_30`, `temp_sealevelpressure_interaction`, `rolling_30_sealevelpressure`, `season_avg_sealevelpressure`, `rolling_3_sealevelpressure_change`.\n",
    "- Ensure production computation is consistent with training (timezone, leap years, dayâ€‘length algorithm) and uses the same scaling/normalization where applicable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
