{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a8d2dda",
   "metadata": {},
   "source": [
    "# Hanoi Weather Data Collection\n",
    "\n",
    "This notebook demonstrates how to collect historical weather data for Hanoi from the Visual Crossing Weather API. We'll gather 10+ years of daily weather data with 33+ features that will be used for temperature forecasting.\n",
    "\n",
    "## Objectives\n",
    "1. Set up API connection to Visual Crossing Weather API\n",
    "2. Collect 10 years of daily weather data for Hanoi\n",
    "3. Understand the 33+ weather features available\n",
    "4. Validate and explore the collected data\n",
    "5. Save data for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1226d002",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cfb96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4767296f",
   "metadata": {},
   "source": [
    "## 2. API Configuration\n",
    "\n",
    "Visual Crossing Weather API provides comprehensive historical weather data. We'll configure our API connection and understand the available parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68beb181",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API Configuration\n",
    "API_KEY = os.getenv('VISUAL_CROSSING_API_KEY')  # Get your free API key from visualcrossing.com\n",
    "BASE_URL = \"https://weather.visualcrossing.com/VisualCrossingWebServices/rest/services/timeline\"\n",
    "LOCATION = \"Hanoi,Vietnam\"\n",
    "\n",
    "if not API_KEY:\n",
    "    print(\"‚ö†Ô∏è Warning: API key not found!\")\n",
    "    print(\"Please set VISUAL_CROSSING_API_KEY in your .env file\")\n",
    "    print(\"You can get a free API key from: https://www.visualcrossing.com/weather/weather-data-services\")\n",
    "    API_KEY = input(\"Or enter your API key here: \")\n",
    "\n",
    "print(f\"API configured for location: {LOCATION}\")\n",
    "print(f\"Base URL: {BASE_URL}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ed1bde",
   "metadata": {},
   "source": [
    "## 3. Weather Data Collection Functions\n",
    "\n",
    "Let's create functions to collect weather data with proper rate limiting and error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HanoiWeatherCollector:\n",
    "    \"\"\"A class to collect weather data for Hanoi from Visual Crossing API.\"\"\"\n",
    "    \n",
    "    def __init__(self, api_key):\n",
    "        self.api_key = api_key\n",
    "        self.base_url = BASE_URL\n",
    "        self.location = LOCATION\n",
    "        self.last_request_time = 0\n",
    "        self.rate_limit_delay = 1.1  # Seconds between requests (stay under rate limits)\n",
    "    \n",
    "    def _rate_limit_wait(self):\n",
    "        \"\"\"Implement rate limiting to avoid exceeding API limits.\"\"\"\n",
    "        current_time = time.time()\n",
    "        time_since_last = current_time - self.last_request_time\n",
    "        \n",
    "        if time_since_last < self.rate_limit_delay:\n",
    "            sleep_time = self.rate_limit_delay - time_since_last\n",
    "            time.sleep(sleep_time)\n",
    "        \n",
    "        self.last_request_time = time.time()\n",
    "    \n",
    "    def fetch_weather_data(self, start_date, end_date, include_hours=False):\n",
    "        \"\"\"Fetch weather data for a specific date range.\"\"\"\n",
    "        self._rate_limit_wait()\n",
    "        \n",
    "        url = f\"{self.base_url}/{self.location}/{start_date}/{end_date}\"\n",
    "        \n",
    "        params = {\n",
    "            'unitGroup': 'metric',\n",
    "            'include': 'days,hours' if include_hours else 'days',\n",
    "            'key': self.api_key,\n",
    "            'contentType': 'json'\n",
    "        }\n",
    "        \n",
    "        try:\n",
    "            print(f\"Fetching data from {start_date} to {end_date}...\")\n",
    "            response = requests.get(url, params=params, timeout=30)\n",
    "            response.raise_for_status()\n",
    "            return response.json()\n",
    "        \n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error fetching data: {e}\")\n",
    "            return None\n",
    "    \n",
    "    def collect_historical_data(self, years=10, include_hours=False):\n",
    "        \"\"\"Collect historical weather data for specified number of years.\"\"\"\n",
    "        end_date = datetime.now()\n",
    "        start_date = end_date - timedelta(days=years * 365)\n",
    "        \n",
    "        print(f\"Collecting {years} years of weather data for {self.location}\")\n",
    "        print(f\"Date range: {start_date.strftime('%Y-%m-%d')} to {end_date.strftime('%Y-%m-%d')}\")\n",
    "        \n",
    "        # Collect data in chunks to avoid API limits (1 year per request)\n",
    "        all_data = []\n",
    "        current_date = start_date\n",
    "        \n",
    "        while current_date < end_date:\n",
    "            chunk_end = min(current_date + timedelta(days=365), end_date)\n",
    "            \n",
    "            start_str = current_date.strftime(\"%Y-%m-%d\")\n",
    "            end_str = chunk_end.strftime(\"%Y-%m-%d\")\n",
    "            \n",
    "            data = self.fetch_weather_data(start_str, end_str, include_hours)\n",
    "            \n",
    "            if data and 'days' in data:\n",
    "                all_data.extend(data['days'])\n",
    "                print(f\"‚úì Collected {len(data['days'])} days\")\n",
    "            else:\n",
    "                print(f\"‚úó Failed to collect data for {start_str} to {end_str}\")\n",
    "            \n",
    "            current_date = chunk_end\n",
    "        \n",
    "        print(f\"\\nTotal data collected: {len(all_data)} days\")\n",
    "        return all_data\n",
    "\n",
    "# Initialize the collector\n",
    "collector = HanoiWeatherCollector(API_KEY)\n",
    "print(\"Weather collector initialized!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb4f698",
   "metadata": {},
   "source": [
    "## 4. Collect 10 Years of Daily Weather Data\n",
    "\n",
    "Now let's collect 10 years of historical daily weather data for Hanoi. This will give us a comprehensive dataset for temperature forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227f077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 10 years of daily weather data\n",
    "print(\"Starting data collection...\")\n",
    "print(\"This may take several minutes due to API rate limiting.\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "raw_data = collector.collect_historical_data(years=10, include_hours=False)\n",
    "\n",
    "if raw_data:\n",
    "    print(f\"\\n‚úÖ Successfully collected {len(raw_data)} days of weather data!\")\n",
    "else:\n",
    "    print(\"‚ùå Failed to collect weather data. Please check your API key and connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1d0479",
   "metadata": {},
   "source": [
    "## 5. Convert to DataFrame and Initial Exploration\n",
    "\n",
    "Let's convert the raw data to a pandas DataFrame and explore its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a9cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "if raw_data:\n",
    "    df = pd.DataFrame(raw_data)\n",
    "    \n",
    "    # Convert datetime column\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    \n",
    "    # Sort by date\n",
    "    df = df.sort_values('datetime').reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Dataset shape: {df.shape}\")\n",
    "    print(f\"Date range: {df['datetime'].min()} to {df['datetime'].max()}\")\n",
    "    print(f\"Number of features: {len(df.columns)}\")\n",
    "    \n",
    "    # Display first few rows\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(df.head())\n",
    "else:\n",
    "    print(\"No data to process. Please run the data collection cell above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d7912d",
   "metadata": {},
   "source": [
    "## 6. Understanding Weather Features (33+ Features)\n",
    "\n",
    "Let's explore all the weather features available in our dataset and understand what each one represents for temperature forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45dd264",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weather feature descriptions\n",
    "feature_descriptions = {\n",
    "    # Temperature Features (Primary targets)\n",
    "    'temp': 'Average temperature (¬∞C) - Our main prediction target',\n",
    "    'tempmax': 'Maximum temperature (¬∞C) - Daily peak temperature',\n",
    "    'tempmin': 'Minimum temperature (¬∞C) - Daily lowest temperature',\n",
    "    'feelslike': 'Feels-like temperature (¬∞C) - Apparent temperature considering humidity and wind',\n",
    "    'dew': 'Dew point temperature (¬∞C) - Temperature at which air becomes saturated',\n",
    "    \n",
    "    # Atmospheric Conditions\n",
    "    'humidity': 'Relative humidity (%) - Amount of moisture in the air',\n",
    "    'pressure': 'Atmospheric pressure (hPa) - Air pressure at sea level',\n",
    "    'visibility': 'Visibility distance (km) - How far you can see clearly',\n",
    "    'cloudcover': 'Cloud coverage (%) - Percentage of sky covered by clouds',\n",
    "    \n",
    "    # Wind Characteristics\n",
    "    'windspeed': 'Wind speed (km/h) - Average wind velocity',\n",
    "    'winddir': 'Wind direction (degrees) - Direction wind is coming from (0-360¬∞)',\n",
    "    'windgust': 'Wind gust speed (km/h) - Maximum wind speed in gusts',\n",
    "    \n",
    "    # Precipitation\n",
    "    'precip': 'Precipitation amount (mm) - Total rainfall/snowfall',\n",
    "    'precipprob': 'Precipitation probability (%) - Chance of precipitation',\n",
    "    'preciptype': 'Precipitation type - Rain, snow, sleet, etc.',\n",
    "    'precipcover': 'Precipitation coverage (%) - Area affected by precipitation',\n",
    "    'snow': 'Snow amount (cm) - Fresh snowfall',\n",
    "    'snowdepth': 'Snow depth on ground (cm) - Accumulated snow',\n",
    "    \n",
    "    # Solar and Radiation\n",
    "    'solarradiation': 'Solar radiation (W/m¬≤) - Solar energy received',\n",
    "    'solarenergy': 'Solar energy (MJ/m¬≤) - Total solar energy for the day',\n",
    "    'uvindex': 'UV Index - Ultraviolet radiation intensity (0-11+ scale)',\n",
    "    \n",
    "    # Celestial and Time\n",
    "    'moonphase': 'Moon phase (0-1) - 0=new moon, 0.25=first quarter, 0.5=full moon, 0.75=last quarter',\n",
    "    'sunrise': 'Sunrise time - When sun rises',\n",
    "    'sunset': 'Sunset time - When sun sets',\n",
    "    \n",
    "    # Weather Conditions (Text Features)\n",
    "    'conditions': 'Weather conditions - Brief description (Clear, Cloudy, Rain, etc.)',\n",
    "    'description': 'Detailed weather description - More comprehensive weather summary',\n",
    "    'icon': 'Weather icon code - Visual representation identifier',\n",
    "    \n",
    "    # Additional Features\n",
    "    'severerisk': 'Severe weather risk (%) - Risk of severe weather events',\n",
    "    'datetime': 'Date and time - Primary time index for our time series'\n",
    "}\n",
    "\n",
    "if 'df' in locals():\n",
    "    print(\"Available Features in Our Dataset:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    available_features = df.columns.tolist()\n",
    "    \n",
    "    for i, feature in enumerate(available_features, 1):\n",
    "        description = feature_descriptions.get(feature, 'Feature description not available')\n",
    "        print(f\"{i:2d}. {feature:15s} - {description}\")\n",
    "    \n",
    "    print(f\"\\nTotal features: {len(available_features)}\")\n",
    "    \n",
    "    # Check data types\n",
    "    print(\"\\nData Types:\")\n",
    "    print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315f45c3",
   "metadata": {},
   "source": [
    "## 7. Data Quality Assessment\n",
    "\n",
    "Let's assess the quality of our collected data by checking for missing values, duplicates, and data distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cebb8e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"DATA QUALITY ASSESSMENT\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Basic statistics\n",
    "    print(f\"Dataset shape: {df.shape[0]:,} rows √ó {df.shape[1]} columns\")\n",
    "    print(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Date range\n",
    "    print(f\"\\nDate Range:\")\n",
    "    print(f\"From: {df['datetime'].min()}\")\n",
    "    print(f\"To:   {df['datetime'].max()}\")\n",
    "    print(f\"Span: {(df['datetime'].max() - df['datetime'].min()).days} days\")\n",
    "    \n",
    "    # Missing values analysis\n",
    "    print(\"\\nMissing Values Analysis:\")\n",
    "    missing_counts = df.isnull().sum()\n",
    "    missing_percent = (missing_counts / len(df)) * 100\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'Feature': missing_counts.index,\n",
    "        'Missing_Count': missing_counts.values,\n",
    "        'Missing_Percent': missing_percent.values\n",
    "    })\n",
    "    \n",
    "    # Show only features with missing values\n",
    "    missing_features = missing_df[missing_df['Missing_Count'] > 0].sort_values('Missing_Percent', ascending=False)\n",
    "    \n",
    "    if len(missing_features) > 0:\n",
    "        print(\"Features with missing values:\")\n",
    "        display(missing_features)\n",
    "    else:\n",
    "        print(\"‚úÖ No missing values found!\")\n",
    "    \n",
    "    # Check for duplicates\n",
    "    duplicates = df.duplicated(subset=['datetime']).sum()\n",
    "    print(f\"\\nDuplicate records: {duplicates}\")\n",
    "    \n",
    "    # Basic statistics for numerical features\n",
    "    print(\"\\nNumerical Features Summary:\")\n",
    "    numerical_cols = df.select_dtypes(include=[np.number]).columns\n",
    "    display(df[numerical_cols].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530f9e9",
   "metadata": {},
   "source": [
    "## 8. Initial Temperature Analysis\n",
    "\n",
    "Let's focus on our primary target variable - temperature - and understand its patterns over the 10-year period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c151527",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Temperature analysis\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    fig.suptitle(\"Hanoi Temperature Analysis (10 Years)\", fontsize=16, fontweight='bold')\n",
    "    \n",
    "    # 1. Temperature time series\n",
    "    axes[0, 0].plot(df['datetime'], df['temp'], alpha=0.7, color='red', linewidth=0.5)\n",
    "    axes[0, 0].set_title('Daily Average Temperature Over Time')\n",
    "    axes[0, 0].set_xlabel('Date')\n",
    "    axes[0, 0].set_ylabel('Temperature (¬∞C)')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add yearly rolling average\n",
    "    df['temp_rolling_365'] = df['temp'].rolling(window=365, center=True).mean()\n",
    "    axes[0, 0].plot(df['datetime'], df['temp_rolling_365'], color='darkred', linewidth=2, label='365-day average')\n",
    "    axes[0, 0].legend()\n",
    "    \n",
    "    # 2. Temperature distribution\n",
    "    axes[0, 1].hist(df['temp'], bins=50, alpha=0.7, color='skyblue', edgecolor='black')\n",
    "    axes[0, 1].axvline(df['temp'].mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {df[\"temp\"].mean():.1f}¬∞C')\n",
    "    axes[0, 1].axvline(df['temp'].median(), color='orange', linestyle='--', linewidth=2, label=f'Median: {df[\"temp\"].median():.1f}¬∞C')\n",
    "    axes[0, 1].set_title('Temperature Distribution')\n",
    "    axes[0, 1].set_xlabel('Temperature (¬∞C)')\n",
    "    axes[0, 1].set_ylabel('Frequency')\n",
    "    axes[0, 1].legend()\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Seasonal patterns\n",
    "    df['month'] = df['datetime'].dt.month\n",
    "    monthly_temp = df.groupby('month')['temp'].agg(['mean', 'min', 'max'])\n",
    "    \n",
    "    months = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "    axes[1, 0].plot(monthly_temp.index, monthly_temp['mean'], marker='o', linewidth=2, markersize=8, color='red', label='Average')\n",
    "    axes[1, 0].fill_between(monthly_temp.index, monthly_temp['min'], monthly_temp['max'], alpha=0.3, color='red', label='Min-Max Range')\n",
    "    axes[1, 0].set_title('Seasonal Temperature Patterns')\n",
    "    axes[1, 0].set_xlabel('Month')\n",
    "    axes[1, 0].set_ylabel('Temperature (¬∞C)')\n",
    "    axes[1, 0].set_xticks(range(1, 13))\n",
    "    axes[1, 0].set_xticklabels(months)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Yearly temperature trends\n",
    "    df['year'] = df['datetime'].dt.year\n",
    "    yearly_temp = df.groupby('year')['temp'].mean()\n",
    "    \n",
    "    axes[1, 1].bar(yearly_temp.index, yearly_temp.values, alpha=0.7, color='green')\n",
    "    axes[1, 1].plot(yearly_temp.index, yearly_temp.values, color='darkgreen', marker='o', linewidth=2, markersize=6)\n",
    "    axes[1, 1].set_title('Average Temperature by Year')\n",
    "    axes[1, 1].set_xlabel('Year')\n",
    "    axes[1, 1].set_ylabel('Average Temperature (¬∞C)')\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Rotate x-axis labels for better readability\n",
    "    axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Print temperature statistics\n",
    "    print(\"\\nHANOI TEMPERATURE STATISTICS (10 Years)\")\n",
    "    print(\"=\" * 45)\n",
    "    print(f\"Average Temperature: {df['temp'].mean():.2f}¬∞C\")\n",
    "    print(f\"Median Temperature:  {df['temp'].median():.2f}¬∞C\")\n",
    "    print(f\"Standard Deviation:  {df['temp'].std():.2f}¬∞C\")\n",
    "    print(f\"Minimum Temperature: {df['temp'].min():.2f}¬∞C\")\n",
    "    print(f\"Maximum Temperature: {df['temp'].max():.2f}¬∞C\")\n",
    "    print(f\"Temperature Range:   {df['temp'].max() - df['temp'].min():.2f}¬∞C\")\n",
    "    \n",
    "    # Seasonal analysis\n",
    "    print(\"\\nSeasonal Temperature Averages:\")\n",
    "    seasons = {\n",
    "        'Winter (Dec-Feb)': [12, 1, 2],\n",
    "        'Spring (Mar-May)': [3, 4, 5],\n",
    "        'Summer (Jun-Aug)': [6, 7, 8],\n",
    "        'Autumn (Sep-Nov)': [9, 10, 11]\n",
    "    }\n",
    "    \n",
    "    for season, months in seasons.items():\n",
    "        season_temp = df[df['month'].isin(months)]['temp'].mean()\n",
    "        print(f\"{season}: {season_temp:.2f}¬∞C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8011e73",
   "metadata": {},
   "source": [
    "## 9. Key Weather Features Correlation Analysis\n",
    "\n",
    "Let's examine how different weather features correlate with temperature to understand which features might be most important for forecasting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27560c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Select key numerical features for correlation analysis\n",
    "    key_features = ['temp', 'tempmax', 'tempmin', 'feelslike', 'humidity', 'pressure', \n",
    "                   'windspeed', 'cloudcover', 'precip', 'solarradiation', 'uvindex', 'moonphase']\n",
    "    \n",
    "    # Filter features that exist in our dataset\n",
    "    available_features = [f for f in key_features if f in df.columns]\n",
    "    \n",
    "    if len(available_features) > 1:\n",
    "        # Correlation matrix\n",
    "        correlation_matrix = df[available_features].corr()\n",
    "        \n",
    "        # Plot correlation heatmap\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        mask = np.triu(correlation_matrix.corr())\n",
    "        sns.heatmap(correlation_matrix, annot=True, cmap='RdBu_r', center=0, \n",
    "                   square=True, mask=mask, cbar_kws={'shrink': 0.8})\n",
    "        plt.title('Weather Features Correlation Matrix\\n(Focus on Temperature Relationships)', \n",
    "                 fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Features most correlated with temperature\n",
    "        temp_correlations = correlation_matrix['temp'].abs().sort_values(ascending=False)\n",
    "        temp_correlations = temp_correlations[temp_correlations.index != 'temp']  # Remove self-correlation\n",
    "        \n",
    "        print(\"\\nFEATURES MOST CORRELATED WITH TEMPERATURE\")\n",
    "        print(\"=\" * 50)\n",
    "        for i, (feature, corr) in enumerate(temp_correlations.head(10).items(), 1):\n",
    "            correlation_strength = \"Strong\" if abs(corr) > 0.7 else \"Moderate\" if abs(corr) > 0.3 else \"Weak\"\n",
    "            direction = \"Positive\" if corr > 0 else \"Negative\"\n",
    "            print(f\"{i:2d}. {feature:15s}: {corr:6.3f} ({direction} {correlation_strength})\")\n",
    "        \n",
    "        # Interesting insights\n",
    "        print(\"\\nüîç KEY INSIGHTS FOR TEMPERATURE FORECASTING:\")\n",
    "        print(\"=\" * 50)\n",
    "        \n",
    "        if 'tempmax' in temp_correlations:\n",
    "            print(f\"‚Ä¢ Maximum temperature correlation: {correlation_matrix.loc['temp', 'tempmax']:.3f}\")\n",
    "            print(\"  ‚Üí Maximum temperature is highly predictive of average temperature\")\n",
    "        \n",
    "        if 'humidity' in temp_correlations:\n",
    "            humidity_corr = correlation_matrix.loc['temp', 'humidity']\n",
    "            print(f\"‚Ä¢ Humidity correlation: {humidity_corr:.3f}\")\n",
    "            if humidity_corr < -0.3:\n",
    "                print(\"  ‚Üí Higher humidity tends to be associated with lower temperatures\")\n",
    "        \n",
    "        if 'solarradiation' in temp_correlations:\n",
    "            solar_corr = correlation_matrix.loc['temp', 'solarradiation']\n",
    "            print(f\"‚Ä¢ Solar radiation correlation: {solar_corr:.3f}\")\n",
    "            if solar_corr > 0.3:\n",
    "                print(\"  ‚Üí More solar radiation typically means higher temperatures\")\n",
    "        \n",
    "        if 'cloudcover' in temp_correlations:\n",
    "            cloud_corr = correlation_matrix.loc['temp', 'cloudcover']\n",
    "            print(f\"‚Ä¢ Cloud cover correlation: {cloud_corr:.3f}\")\n",
    "            if cloud_corr < -0.2:\n",
    "                print(\"  ‚Üí More clouds generally associated with cooler temperatures\")\n",
    "    \n",
    "    else:\n",
    "        print(\"Insufficient numerical features for correlation analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053b3e00",
   "metadata": {},
   "source": [
    "## 10. Text Features Analysis\n",
    "\n",
    "Let's explore the text-based weather features (conditions, description) that we'll need to process for machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931b636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    print(\"TEXT FEATURES ANALYSIS\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    # Analyze weather conditions\n",
    "    if 'conditions' in df.columns:\n",
    "        print(\"\\n1. WEATHER CONDITIONS:\")\n",
    "        conditions_counts = df['conditions'].value_counts()\n",
    "        print(f\"Total unique conditions: {len(conditions_counts)}\")\n",
    "        print(\"\\nTop 10 most common weather conditions:\")\n",
    "        for i, (condition, count) in enumerate(conditions_counts.head(10).items(), 1):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"{i:2d}. {condition:25s}: {count:4d} days ({percentage:5.1f}%)\")\n",
    "        \n",
    "        # Average temperature by weather condition\n",
    "        temp_by_condition = df.groupby('conditions')['temp'].agg(['mean', 'std', 'count']).round(2)\n",
    "        temp_by_condition = temp_by_condition[temp_by_condition['count'] >= 10]  # Only conditions with 10+ occurrences\n",
    "        temp_by_condition = temp_by_condition.sort_values('mean', ascending=False)\n",
    "        \n",
    "        print(\"\\nAverage temperature by weather condition (conditions with 10+ occurrences):\")\n",
    "        print(f\"{'Condition':<25} {'Avg Temp (¬∞C)':<12} {'Std Dev':<8} {'Count':<6}\")\n",
    "        print(\"-\" * 55)\n",
    "        for condition, row in temp_by_condition.head(15).iterrows():\n",
    "            print(f\"{condition:<25} {row['mean']:8.1f}     {row['std']:6.1f}   {row['count']:4.0f}\")\n",
    "    \n",
    "    # Analyze weather descriptions\n",
    "    if 'description' in df.columns:\n",
    "        print(\"\\n\\n2. WEATHER DESCRIPTIONS:\")\n",
    "        description_counts = df['description'].value_counts()\n",
    "        print(f\"Total unique descriptions: {len(description_counts)}\")\n",
    "        print(\"\\nTop 10 most common weather descriptions:\")\n",
    "        for i, (desc, count) in enumerate(description_counts.head(10).items(), 1):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            # Truncate long descriptions\n",
    "            desc_short = desc[:50] + \"...\" if len(desc) > 50 else desc\n",
    "            print(f\"{i:2d}. {desc_short:<53}: {count:4d} days ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Weather icons analysis\n",
    "    if 'icon' in df.columns:\n",
    "        print(\"\\n\\n3. WEATHER ICONS:\")\n",
    "        icon_counts = df['icon'].value_counts()\n",
    "        print(f\"Total unique icons: {len(icon_counts)}\")\n",
    "        print(\"\\nAll weather icon types:\")\n",
    "        for i, (icon, count) in enumerate(icon_counts.items(), 1):\n",
    "            percentage = (count / len(df)) * 100\n",
    "            print(f\"{i:2d}. {icon:<20}: {count:4d} days ({percentage:5.1f}%)\")\n",
    "    \n",
    "    # Create a visualization for weather conditions\n",
    "    if 'conditions' in df.columns:\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Top weather conditions\n",
    "        top_conditions = conditions_counts.head(8)\n",
    "        plt.subplot(2, 1, 1)\n",
    "        top_conditions.plot(kind='bar', color='skyblue', edgecolor='black')\n",
    "        plt.title('Most Common Weather Conditions in Hanoi (10 Years)', fontweight='bold')\n",
    "        plt.xlabel('Weather Conditions')\n",
    "        plt.ylabel('Number of Days')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Temperature distribution by weather condition\n",
    "        plt.subplot(2, 1, 2)\n",
    "        top_5_conditions = conditions_counts.head(5).index\n",
    "        temp_data = [df[df['conditions'] == condition]['temp'].values for condition in top_5_conditions]\n",
    "        plt.boxplot(temp_data, labels=top_5_conditions)\n",
    "        plt.title('Temperature Distribution by Weather Condition', fontweight='bold')\n",
    "        plt.xlabel('Weather Conditions')\n",
    "        plt.ylabel('Temperature (¬∞C)')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872158df",
   "metadata": {},
   "source": [
    "## 11. Save Collected Data\n",
    "\n",
    "Let's save our collected data to the appropriate directory for further processing and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430e2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'df' in locals():\n",
    "    # Create data directory if it doesn't exist\n",
    "    os.makedirs('../data/raw/daily', exist_ok=True)\n",
    "    \n",
    "    # Generate filename with timestamp\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"hanoi_weather_daily_10years_{timestamp}.csv\"\n",
    "    filepath = f\"../data/raw/daily/{filename}\"\n",
    "    \n",
    "    # Save the data\n",
    "    df.to_csv(filepath, index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Data successfully saved to: {filepath}\")\n",
    "    print(f\"üìä Dataset summary:\")\n",
    "    print(f\"   ‚Ä¢ Records: {len(df):,}\")\n",
    "    print(f\"   ‚Ä¢ Features: {len(df.columns)}\")\n",
    "    print(f\"   ‚Ä¢ Date range: {df['datetime'].min().date()} to {df['datetime'].max().date()}\")\n",
    "    print(f\"   ‚Ä¢ File size: {os.path.getsize(filepath) / 1024**2:.2f} MB\")\n",
    "    \n",
    "    # Also save feature descriptions for reference\n",
    "    feature_info_file = f\"../data/raw/daily/feature_descriptions_{timestamp}.json\"\n",
    "    with open(feature_info_file, 'w') as f:\n",
    "        json.dump(feature_descriptions, f, indent=2)\n",
    "    \n",
    "    print(f\"üìù Feature descriptions saved to: {feature_info_file}\")\n",
    "    \n",
    "    # Create a summary report\n",
    "    summary_report = {\n",
    "        'collection_date': datetime.now().isoformat(),\n",
    "        'location': LOCATION,\n",
    "        'data_source': 'Visual Crossing Weather API',\n",
    "        'records_collected': len(df),\n",
    "        'features_count': len(df.columns),\n",
    "        'date_range': {\n",
    "            'start': df['datetime'].min().isoformat(),\n",
    "            'end': df['datetime'].max().isoformat(),\n",
    "            'days': (df['datetime'].max() - df['datetime'].min()).days\n",
    "        },\n",
    "        'temperature_stats': {\n",
    "            'mean': float(df['temp'].mean()),\n",
    "            'std': float(df['temp'].std()),\n",
    "            'min': float(df['temp'].min()),\n",
    "            'max': float(df['temp'].max())\n",
    "        },\n",
    "        'missing_values': df.isnull().sum().to_dict(),\n",
    "        'data_quality': 'Good' if df.isnull().sum().sum() < len(df) * 0.05 else 'Needs attention'\n",
    "    }\n",
    "    \n",
    "    summary_file = f\"../data/raw/daily/collection_summary_{timestamp}.json\"\n",
    "    with open(summary_file, 'w') as f:\n",
    "        json.dump(summary_report, f, indent=2, default=str)\n",
    "    \n",
    "    print(f\"üìã Collection summary saved to: {summary_file}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No data to save. Please run the data collection cells above first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7f176f",
   "metadata": {},
   "source": [
    "## 12. Next Steps and Key Insights\n",
    "\n",
    "### What We've Accomplished:\n",
    "1. ‚úÖ Collected 10 years of daily weather data for Hanoi\n",
    "2. ‚úÖ Identified 33+ weather features for temperature forecasting\n",
    "3. ‚úÖ Analyzed temperature patterns and seasonality\n",
    "4. ‚úÖ Examined feature correlations and relationships\n",
    "5. ‚úÖ Processed text-based weather features\n",
    "6. ‚úÖ Saved clean, structured data for modeling\n",
    "\n",
    "### Key Insights from Hanoi Weather Data:\n",
    "\n",
    "**Temperature Patterns:**\n",
    "- Hanoi exhibits strong seasonal variation typical of a subtropical climate\n",
    "- Summer months (June-August) are hottest, winter months (December-February) are coolest\n",
    "- Daily temperature variations provide rich information for forecasting\n",
    "\n",
    "**Important Features for Forecasting:**\n",
    "- Temperature-related features (tempmax, tempmin, feelslike) are highly correlated\n",
    "- Atmospheric conditions (humidity, pressure, cloudcover) show significant relationships\n",
    "- Solar radiation and weather conditions are key predictors\n",
    "- Text features (conditions, descriptions) contain valuable categorical information\n",
    "\n",
    "### Next Steps:\n",
    "1. **Data Understanding & EDA**: Deep dive into feature relationships and patterns\n",
    "2. **Data Processing**: Handle missing values, feature encoding, normalization\n",
    "3. **Feature Engineering**: Create lag features, rolling statistics, seasonal components\n",
    "4. **Model Development**: Build and train forecasting models\n",
    "5. **Model Evaluation**: Test different algorithms and hyperparameters\n",
    "\n",
    "### Recommendations for Temperature Forecasting:\n",
    "- Use multiple temperature features (max, min, average) as predictors\n",
    "- Incorporate lag features (previous days' temperatures)\n",
    "- Consider seasonal and cyclical patterns\n",
    "- Process text features using NLP techniques\n",
    "- Create ensemble models combining different algorithms\n",
    "\n",
    "This dataset provides an excellent foundation for building accurate temperature forecasting models for Hanoi!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
