{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efe63d81",
   "metadata": {},
   "source": [
    "# Hanoi Weather Data - Model Training\n",
    "\n",
    "This section focuses on training and evaluating predictive models for temperature forecasting using the engineered features from the previous step. The goal is to identify the most robust and generalizable model through proper validation, hyperparameter tuning, and performance benchmarking.\n",
    "\n",
    "## Objectives\n",
    "1. Split data into train / validation / test sets — ensuring no temporal data leakage\n",
    "2. Train baseline and advanced ML models (e.g., Linear Regression, Random Forest, XGBoost, LightGBM, etc.)\n",
    "3. Perform hyperparameter tuning using frameworks like Optuna or GridSearchCV\n",
    "4. Evaluate model performance using regression metrics: RMSE, MAE, MAPE, R²\n",
    "5. Analyze overfitting / underfitting behavior using learning curves\n",
    "6. Select and save the best-performing model for deployment or forecasting pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e9ee54",
   "metadata": {},
   "source": [
    "## 1. Setup and Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "5915ce48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import library for model training\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import TimeSeriesSplit, RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.inspection import permutation_importance\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from xgboost import XGBRegressor\n",
    "from scipy.stats import uniform, randint\n",
    "import optuna\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Loading processed data\n",
    "df = pd.read_csv('../data/processed/feature_engineering_daily_data.csv', index_col='datetime')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d52dfd4d",
   "metadata": {},
   "source": [
    "## 2. Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "528e69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['target'])\n",
    "y = df['target']\n",
    "\n",
    "cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "num_cols = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# ---------- 1) Khóa schema OHE toàn cục ----------\n",
    "ohe_template = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "ohe_template.fit(X[cat_cols])\n",
    "fixed_categories = ohe_template.categories_\n",
    "\n",
    "def make_preprocessor():\n",
    "    num_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())\n",
    "    ])\n",
    "    cat_pipe = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "        ('ohe', OneHotEncoder(handle_unknown='ignore',\n",
    "                              sparse_output=False,\n",
    "                              categories=fixed_categories))\n",
    "    ])\n",
    "    return ColumnTransformer([\n",
    "        ('num', num_pipe, num_cols),\n",
    "        ('cat', cat_pipe, cat_cols)\n",
    "    ], remainder='drop')\n",
    "\n",
    "# ---------- 2) Cố định mặt nạ VarianceThreshold từ FOLD ĐẦU ----------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "first_train_idx, first_test_idx = next(tscv.split(X))\n",
    "\n",
    "# Fit preprocessor + VT trên fold đầu\n",
    "preprocessor = make_preprocessor()\n",
    "preprocessor.fit(X.iloc[first_train_idx], y.iloc[first_train_idx])\n",
    "X_first_train_trans = preprocessor.transform(X.iloc[first_train_idx])\n",
    "vt = VarianceThreshold(threshold=0.0).fit(X_first_train_trans)\n",
    "vt_support_mask = vt.get_support()\n",
    "feat_names_all = preprocessor.get_feature_names_out()\n",
    "feat_names_after_vt = feat_names_all[vt_support_mask]\n",
    "\n",
    "def apply_vt_mask(X_mat, mask=vt_support_mask):\n",
    "    return X_mat[:, mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "28c1077e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BẮT ĐẦU TUNING XGBoost với Optuna...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-27 00:09:08,723] A new study created in memory with name: no-name-c62e1665-c252-4dd5-ab55-b6106d5dd1d6\n",
      "[W 2025-10-27 00:09:13,001] Trial 0 failed with parameters: {'n_estimators': 364, 'max_depth': 4, 'learning_rate': 0.010390403084233219, 'subsample': 0.5631350185983126, 'colsample_bytree': 0.6332026967287642, 'min_child_weight': 2, 'reg_alpha': 7.406517216782404, 'reg_lambda': 6.451307621434087} because of the following error: KeyboardInterrupt().\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py\", line 201, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_11056\\4098447385.py\", line 39, in objective\n",
      "    model.fit(X_train_t, y_train)\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1247, in fit\n",
      "    self._Booster = train(\n",
      "                    ^^^^^^\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 729, in inner_f\n",
      "    return func(**kwargs)\n",
      "           ^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py\", line 183, in train\n",
      "    bst.update(dtrain, iteration=i, fobj=obj)\n",
      "  File \"c:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py\", line 2247, in update\n",
      "    _LIB.XGBoosterUpdateOneIter(\n",
      "KeyboardInterrupt\n",
      "[W 2025-10-27 00:09:13,007] Trial 0 failed with value None.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 48\u001b[0m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# Tạo study và tối ưu hóa\u001b[39;00m\n\u001b[0;32m     47\u001b[0m study \u001b[38;5;241m=\u001b[39m optuna\u001b[38;5;241m.\u001b[39mcreate_study(direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaximize\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 48\u001b[0m \u001b[43mstudy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Tương đương n_iter=100\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;66;03m# Lấy tham số tốt nhất\u001b[39;00m\n\u001b[0;32m     51\u001b[0m best_params \u001b[38;5;241m=\u001b[39m study\u001b[38;5;241m.\u001b[39mbest_params\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\study.py:490\u001b[0m, in \u001b[0;36mStudy.optimize\u001b[1;34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m    388\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\n\u001b[0;32m    389\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    390\u001b[0m     func: ObjectiveFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    397\u001b[0m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    398\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    399\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[0;32m    400\u001b[0m \n\u001b[0;32m    401\u001b[0m \u001b[38;5;124;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[38;5;124;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[0;32m    489\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 490\u001b[0m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    491\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    493\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    494\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    495\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    496\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    497\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:63\u001b[0m, in \u001b[0;36m_optimize\u001b[1;34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[0m\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 63\u001b[0m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     65\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     67\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     68\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     69\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     71\u001b[0m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     73\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:160\u001b[0m, in \u001b[0;36m_optimize_sequential\u001b[1;34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[0m\n\u001b[0;32m    157\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 160\u001b[0m     frozen_trial_id \u001b[38;5;241m=\u001b[39m \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[0;32m    166\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:258\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShould not reach.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    253\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    254\u001b[0m     updated_state \u001b[38;5;241m==\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mFAIL\n\u001b[0;32m    255\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    256\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[0;32m    257\u001b[0m ):\n\u001b[1;32m--> 258\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[0;32m    259\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m trial\u001b[38;5;241m.\u001b[39m_trial_id\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\optuna\\study\\_optimize.py:201\u001b[0m, in \u001b[0;36m_run_trial\u001b[1;34m(study, func, catch)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial\u001b[38;5;241m.\u001b[39m_trial_id, study\u001b[38;5;241m.\u001b[39m_storage):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m         value_or_values \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mTrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[0;32m    204\u001b[0m         state \u001b[38;5;241m=\u001b[39m TrialState\u001b[38;5;241m.\u001b[39mPRUNED\n",
      "Cell \u001b[1;32mIn[54], line 39\u001b[0m, in \u001b[0;36mobjective\u001b[1;34m(trial)\u001b[0m\n\u001b[0;32m     36\u001b[0m X_test_t \u001b[38;5;241m=\u001b[39m apply_vt_mask(prep_tune\u001b[38;5;241m.\u001b[39mtransform(X_test))\n\u001b[0;32m     38\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[1;32m---> 39\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_t\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test_t)\n\u001b[0;32m     41\u001b[0m r2 \u001b[38;5;241m=\u001b[39m r2_score(y_test, y_pred)\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\sklearn.py:1247\u001b[0m, in \u001b[0;36mXGBModel.fit\u001b[1;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[0;32m   1244\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1245\u001b[0m     obj \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_Booster \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1248\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1249\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dmatrix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_num_boosting_rounds\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1251\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mevals_result\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mxgb_model\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1258\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1261\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_evaluation_result(evals_result)\n\u001b[0;32m   1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:729\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    727\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[0;32m    728\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[1;32m--> 729\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mbefore_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    182\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m--> 183\u001b[0m \u001b[43mbst\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfobj\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cb_container\u001b[38;5;241m.\u001b[39mafter_iteration(bst, i, dtrain, evals):\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ADMIN\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:2247\u001b[0m, in \u001b[0;36mBooster.update\u001b[1;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[0;32m   2243\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_dmatrix_features(dtrain)\n\u001b[0;32m   2245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fobj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2246\u001b[0m     _check_call(\n\u001b[1;32m-> 2247\u001b[0m         \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXGBoosterUpdateOneIter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2248\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mc_int\u001b[49m\u001b[43m(\u001b[49m\u001b[43miteration\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\n\u001b[0;32m   2249\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2250\u001b[0m     )\n\u001b[0;32m   2251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2252\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(dtrain, output_margin\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"BẮT ĐẦU TUNING XGBoost với Optuna...\")\n",
    "\n",
    "# Dùng 70-80% dữ liệu đầu để tuning\n",
    "train_ratio = 0.8\n",
    "split_idx = int(train_ratio * len(X))\n",
    "X_tune, y_tune = X.iloc[:split_idx], y.iloc[:split_idx]\n",
    "\n",
    "# Preprocess cố định\n",
    "prep_tune = make_preprocessor()\n",
    "prep_tune.fit(X_tune, y_tune)\n",
    "X_tune_t = apply_vt_mask(prep_tune.transform(X_tune))\n",
    "\n",
    "# Hàm objective cho Optuna\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 12),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    all_r2 = []\n",
    "    for tr_idx, te_idx in tscv.split(X_tune):\n",
    "        X_train, X_test = X_tune.iloc[tr_idx], X_tune.iloc[te_idx]\n",
    "        y_train, y_test = y_tune.iloc[tr_idx], y_tune.iloc[te_idx]\n",
    "\n",
    "        X_train_t = apply_vt_mask(prep_tune.transform(X_train))\n",
    "        X_test_t = apply_vt_mask(prep_tune.transform(X_test))\n",
    "\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train_t, y_train)\n",
    "        y_pred = model.predict(X_test_t)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        all_r2.append(r2)\n",
    "\n",
    "    return np.mean(all_r2)\n",
    "\n",
    "# Tạo study và tối ưu hóa\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25)  # Tương đương n_iter=100\n",
    "\n",
    "# Lấy tham số tốt nhất\n",
    "best_params = study.best_params\n",
    "print(\"HOÀN THÀNH TUNING! R2 tốt nhất:\", study.best_value)\n",
    "print(\"Tham số tốt nhất:\", best_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ea9ee8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.08207254032851698, 'subsample': 0.9160744838218801, 'colsample_bytree': 0.9125188448842537, 'min_child_weight': 9, 'reg_alpha': 7.734783954873539, 'reg_lambda': 3.1988045223999775}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dbffba39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV VÒNG 1: DÙNG MODEL ĐÃ TUNED + Permutation Importance ===\n",
      "Fold 1: RMSE=2.785  R2=0.702\n",
      "Fold 2: RMSE=2.523  R2=0.721\n",
      "Fold 3: RMSE=2.368  R2=0.796\n",
      "Fold 4: RMSE=2.550  R2=0.750\n",
      "Fold 5: RMSE=2.196  R2=0.798\n",
      "\n",
      "=== KẾT QUẢ TỔNG KẾT CV VÒNG 1 ===\n",
      "Avg RMSE: 2.484 ± 0.196\n",
      "Avg MAE: 1.981 ± 0.139\n",
      "Avg R2: 0.753 ± 0.039\n"
     ]
    }
   ],
   "source": [
    "# ---------- 3) CV vòng 1: DÙNG MODEL ĐÃ TUNED (KHÔNG TUNING LẠI) ----------\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "all_rmse, all_mae, all_r2 = [], [], []\n",
    "perm_importances_list = []\n",
    "\n",
    "print(\"\\n=== CV VÒNG 1: DÙNG MODEL ĐÃ TUNED + Permutation Importance ===\")\n",
    "for fold, (tr_idx, te_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_train, y_test = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "    preprocessor = make_preprocessor()\n",
    "    preprocessor.fit(X_train, y_train)\n",
    "    X_train_t = apply_vt_mask(preprocessor.transform(X_train))\n",
    "    X_test_t  = apply_vt_mask(preprocessor.transform(X_test))\n",
    "\n",
    "    # DÙNG MODEL ĐÃ TUNED\n",
    "    model = XGBRegressor(**best_params, random_state=42, n_jobs=-1, tree_method='hist')\n",
    "    model.fit(X_train_t, y_train)\n",
    "    y_pred = model.predict(X_test_t)\n",
    "\n",
    "    # Metrics\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    all_rmse.append(rmse); all_mae.append(mae); all_r2.append(r2)\n",
    "\n",
    "    # Permutation Importance\n",
    "    perm = permutation_importance(model, X_test_t, y_test, n_repeats=3, random_state=42, n_jobs=-1)\n",
    "    perm_importances_list.append(perm.importances_mean)\n",
    "\n",
    "    print(f\"Fold {fold}: RMSE={rmse:.3f}  R2={r2:.3f}\")\n",
    "# Tổng kết CV vòng 1\n",
    "print(\"\\n=== KẾT QUẢ TỔNG KẾT CV VÒNG 1 ===\")\n",
    "print(f\"Avg RMSE: {np.mean(all_rmse):.3f} ± {np.std(all_rmse):.3f}\")\n",
    "print(f\"Avg MAE: {np.mean(all_mae):.3f} ± {np.std(all_mae):.3f}\")\n",
    "print(f\"Avg R2: {np.mean(all_r2):.3f} ± {np.std(all_r2):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6393ea3e",
   "metadata": {},
   "source": [
    "Fold 1: RMSE=2.894  R2=0.678\n",
    "Fold 2: RMSE=2.580  R2=0.708\n",
    "Fold 3: RMSE=2.512  R2=0.770\n",
    "Fold 4: RMSE=2.653  R2=0.730\n",
    "Fold 5: RMSE=2.224  R2=0.793\n",
    "\n",
    "=== CV VÒNG 1: DÙNG MODEL ĐÃ TUNED + Permutation Importance ===\n",
    "Fold 1: RMSE=2.841  R2=0.690\n",
    "Fold 2: RMSE=2.507  R2=0.724\n",
    "Fold 3: RMSE=2.385  R2=0.793\n",
    "Fold 4: RMSE=2.611  R2=0.738\n",
    "Fold 5: RMSE=2.191  R2=0.799"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad695a68",
   "metadata": {},
   "source": [
    "## 3. Selecting top K features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8c5aaa87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top-54 features được chọn từ model đã tuning.\n"
     ]
    }
   ],
   "source": [
    "# === CHỌN TOP-K TỪ TRUNG BÌNH ===\n",
    "avg_perm = np.mean(perm_importances_list, axis=0)\n",
    "order = np.argsort(avg_perm)[::-1]\n",
    "cumsum = np.cumsum(avg_perm[order]); cumsum /= cumsum[-1]\n",
    "top_k = np.argmax(cumsum >= 0.95) + 1\n",
    "top_idx = order[:top_k]\n",
    "\n",
    "print(f\"\\nTop-{top_k} features được chọn từ model đã tuning.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25c1bd36",
   "metadata": {},
   "source": [
    "## 4. Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "06a2eb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 22:57:08,554] A new study created in memory with name: no-name-45814b0f-b27c-4051-86b8-e2c40deac0a8\n",
      "[I 2025-10-26 22:57:10,105] Trial 0 finished with value: 0.7384317769252629 and parameters: {'n_estimators': 201, 'max_depth': 3, 'learning_rate': 0.13275274087292344, 'subsample': 0.9834444641994783, 'colsample_bytree': 0.7979757207590283, 'min_child_weight': 9, 'reg_alpha': 4.118050818285707, 'reg_lambda': 0.7057656565877779}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:13,647] Trial 1 finished with value: 0.7382287647247276 and parameters: {'n_estimators': 417, 'max_depth': 7, 'learning_rate': 0.11363134494163409, 'subsample': 0.5821708951975614, 'colsample_bytree': 0.5243539960101882, 'min_child_weight': 9, 'reg_alpha': 2.8034329538873126, 'reg_lambda': 3.7972325348045466}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:16,471] Trial 2 finished with value: 0.7263245905990934 and parameters: {'n_estimators': 850, 'max_depth': 3, 'learning_rate': 0.10780403408244926, 'subsample': 0.6186653540276409, 'colsample_bytree': 0.8992349220432739, 'min_child_weight': 6, 'reg_alpha': 3.599812714095818, 'reg_lambda': 5.521193520516197}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:19,071] Trial 3 finished with value: 0.5861698945166138 and parameters: {'n_estimators': 62, 'max_depth': 10, 'learning_rate': 0.014737915356912613, 'subsample': 0.6761863328666828, 'colsample_bytree': 0.7372183843390914, 'min_child_weight': 2, 'reg_alpha': 8.063170070735307, 'reg_lambda': 1.7480234964870123}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:21,656] Trial 4 finished with value: 0.7274296243581567 and parameters: {'n_estimators': 441, 'max_depth': 5, 'learning_rate': 0.17566411497573833, 'subsample': 0.8538011861613204, 'colsample_bytree': 0.9351862693448815, 'min_child_weight': 5, 'reg_alpha': 8.53188605039719, 'reg_lambda': 2.176286318784814}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:27,090] Trial 5 finished with value: 0.7312238444422545 and parameters: {'n_estimators': 320, 'max_depth': 9, 'learning_rate': 0.035669465751168465, 'subsample': 0.5552092338922648, 'colsample_bytree': 0.8678471693344693, 'min_child_weight': 3, 'reg_alpha': 7.995631139889687, 'reg_lambda': 6.513648664706392}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:31,829] Trial 6 finished with value: 0.7268306409745817 and parameters: {'n_estimators': 735, 'max_depth': 6, 'learning_rate': 0.11268498431635092, 'subsample': 0.5547679351855164, 'colsample_bytree': 0.9051993218551013, 'min_child_weight': 5, 'reg_alpha': 3.1087573933607593, 'reg_lambda': 8.065344034325092}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:34,453] Trial 7 finished with value: 0.7260967792761492 and parameters: {'n_estimators': 333, 'max_depth': 6, 'learning_rate': 0.160219339476716, 'subsample': 0.7029797207687081, 'colsample_bytree': 0.5972956535014715, 'min_child_weight': 10, 'reg_alpha': 0.7199104790182242, 'reg_lambda': 2.1203302971754825}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:38,568] Trial 8 finished with value: 0.7182818940963678 and parameters: {'n_estimators': 674, 'max_depth': 7, 'learning_rate': 0.21666582775424434, 'subsample': 0.6494283307424931, 'colsample_bytree': 0.7093418304651713, 'min_child_weight': 8, 'reg_alpha': 5.9833776434529184, 'reg_lambda': 0.574558654576468}. Best is trial 0 with value: 0.7384317769252629.\n",
      "[I 2025-10-26 22:57:40,649] Trial 9 finished with value: 0.7479321856475165 and parameters: {'n_estimators': 579, 'max_depth': 3, 'learning_rate': 0.05076774526351914, 'subsample': 0.7734789583653806, 'colsample_bytree': 0.5868275048323857, 'min_child_weight': 7, 'reg_alpha': 4.155811366899982, 'reg_lambda': 7.041863299354598}. Best is trial 9 with value: 0.7479321856475165.\n",
      "[I 2025-10-26 22:57:43,180] Trial 10 finished with value: 0.7420225784805563 and parameters: {'n_estimators': 595, 'max_depth': 4, 'learning_rate': 0.04215299736256032, 'subsample': 0.8052357264809932, 'colsample_bytree': 0.6274447078626928, 'min_child_weight': 7, 'reg_alpha': 6.012002026225109, 'reg_lambda': 9.990847805469452}. Best is trial 9 with value: 0.7479321856475165.\n",
      "[I 2025-10-26 22:57:45,644] Trial 11 finished with value: 0.7440394403301014 and parameters: {'n_estimators': 603, 'max_depth': 4, 'learning_rate': 0.04249923082081228, 'subsample': 0.8160204148139032, 'colsample_bytree': 0.6317004334371673, 'min_child_weight': 7, 'reg_alpha': 6.008499176485579, 'reg_lambda': 9.6070002801019}. Best is trial 9 with value: 0.7479321856475165.\n",
      "[I 2025-10-26 22:57:49,083] Trial 12 finished with value: 0.7494153561428611 and parameters: {'n_estimators': 993, 'max_depth': 4, 'learning_rate': 0.018736585096482544, 'subsample': 0.8962423160632083, 'colsample_bytree': 0.6292686758142253, 'min_child_weight': 7, 'reg_alpha': 5.636815984552443, 'reg_lambda': 9.818481815094415}. Best is trial 12 with value: 0.7494153561428611.\n",
      "[I 2025-10-26 22:57:52,418] Trial 13 finished with value: 0.7536251594795467 and parameters: {'n_estimators': 998, 'max_depth': 4, 'learning_rate': 0.01728195441335375, 'subsample': 0.9206485510564396, 'colsample_bytree': 0.5115433180291948, 'min_child_weight': 4, 'reg_alpha': 1.0642938434219333, 'reg_lambda': 7.84101047261702}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:57:56,696] Trial 14 finished with value: 0.7534750477177938 and parameters: {'n_estimators': 995, 'max_depth': 5, 'learning_rate': 0.01089158867748018, 'subsample': 0.9354145225762621, 'colsample_bytree': 0.5056759052670531, 'min_child_weight': 4, 'reg_alpha': 0.40186853646707377, 'reg_lambda': 8.415720724571766}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:00,881] Trial 15 finished with value: 0.7529166927986282 and parameters: {'n_estimators': 972, 'max_depth': 5, 'learning_rate': 0.0100127446885636, 'subsample': 0.9762078983713143, 'colsample_bytree': 0.5008868069344906, 'min_child_weight': 3, 'reg_alpha': 0.013573564147531414, 'reg_lambda': 8.223346541956268}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:12,726] Trial 16 finished with value: 0.7412410959251534 and parameters: {'n_estimators': 868, 'max_depth': 8, 'learning_rate': 0.024304194317801182, 'subsample': 0.9074696845921492, 'colsample_bytree': 0.5373279398802389, 'min_child_weight': 1, 'reg_alpha': 1.595914180515894, 'reg_lambda': 4.697230219136475}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:16,775] Trial 17 finished with value: 0.7526479983315173 and parameters: {'n_estimators': 833, 'max_depth': 5, 'learning_rate': 0.010381587767093617, 'subsample': 0.9281150245576432, 'colsample_bytree': 0.6769006360976104, 'min_child_weight': 4, 'reg_alpha': 1.826566390969607, 'reg_lambda': 8.380880600650194}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:20,928] Trial 18 finished with value: 0.7427890873559939 and parameters: {'n_estimators': 767, 'max_depth': 5, 'learning_rate': 0.025585809160264057, 'subsample': 0.8667832326967454, 'colsample_bytree': 0.9957870868072602, 'min_child_weight': 4, 'reg_alpha': 1.7292557114207359, 'reg_lambda': 6.872257518142227}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:27,264] Trial 19 finished with value: 0.7460400395476754 and parameters: {'n_estimators': 944, 'max_depth': 6, 'learning_rate': 0.06673520333630742, 'subsample': 0.7364594636579479, 'colsample_bytree': 0.7943209901701909, 'min_child_weight': 1, 'reg_alpha': 0.11603907388323131, 'reg_lambda': 5.634098393658691}. Best is trial 13 with value: 0.7536251594795467.\n",
      "[I 2025-10-26 22:58:30,474] Trial 20 finished with value: 0.7565922124939142 and parameters: {'n_estimators': 893, 'max_depth': 4, 'learning_rate': 0.014237017765216254, 'subsample': 0.9984348918153227, 'colsample_bytree': 0.5486052554241, 'min_child_weight': 3, 'reg_alpha': 1.0558463083964675, 'reg_lambda': 8.677557310643799}. Best is trial 20 with value: 0.7565922124939142.\n",
      "[I 2025-10-26 22:58:33,634] Trial 21 finished with value: 0.7576251723645792 and parameters: {'n_estimators': 893, 'max_depth': 4, 'learning_rate': 0.014591334324225096, 'subsample': 0.9961238518714451, 'colsample_bytree': 0.5588636842529369, 'min_child_weight': 3, 'reg_alpha': 1.2343923217549904, 'reg_lambda': 8.637046545491168}. Best is trial 21 with value: 0.7576251723645792.\n",
      "[I 2025-10-26 22:58:36,818] Trial 22 finished with value: 0.7550141517212119 and parameters: {'n_estimators': 892, 'max_depth': 4, 'learning_rate': 0.016011361076555555, 'subsample': 0.9869689443068201, 'colsample_bytree': 0.5706797658188173, 'min_child_weight': 3, 'reg_alpha': 2.3007380700584035, 'reg_lambda': 8.986297901986138}. Best is trial 21 with value: 0.7576251723645792.\n",
      "[I 2025-10-26 22:58:39,171] Trial 23 finished with value: 0.7556201219379434 and parameters: {'n_estimators': 763, 'max_depth': 3, 'learning_rate': 0.02755893241361283, 'subsample': 0.9942082364726905, 'colsample_bytree': 0.5690780503851479, 'min_child_weight': 2, 'reg_alpha': 2.496654638151924, 'reg_lambda': 9.108438442017276}. Best is trial 21 with value: 0.7576251723645792.\n",
      "[I 2025-10-26 22:58:41,660] Trial 24 finished with value: 0.7562299081368234 and parameters: {'n_estimators': 771, 'max_depth': 3, 'learning_rate': 0.02442542906779013, 'subsample': 0.9591831219539204, 'colsample_bytree': 0.6785371113008299, 'min_child_weight': 2, 'reg_alpha': 2.4647863358507194, 'reg_lambda': 9.103309664772992}. Best is trial 21 with value: 0.7576251723645792.\n",
      "[I 2025-10-26 22:58:43,862] Trial 25 finished with value: 0.7606075771753579 and parameters: {'n_estimators': 686, 'max_depth': 3, 'learning_rate': 0.013163805903287314, 'subsample': 0.9551109574833015, 'colsample_bytree': 0.6562845886539105, 'min_child_weight': 2, 'reg_alpha': 9.660718118972792, 'reg_lambda': 7.4209507118897164}. Best is trial 25 with value: 0.7606075771753579.\n",
      "[I 2025-10-26 22:58:46,654] Trial 26 finished with value: 0.755237141988273 and parameters: {'n_estimators': 693, 'max_depth': 4, 'learning_rate': 0.012997898530941994, 'subsample': 0.8697315703810862, 'colsample_bytree': 0.665872455625363, 'min_child_weight': 1, 'reg_alpha': 9.586323874072148, 'reg_lambda': 7.190782289833191}. Best is trial 25 with value: 0.7606075771753579.\n",
      "[I 2025-10-26 22:58:48,895] Trial 27 finished with value: 0.7583814388244117 and parameters: {'n_estimators': 666, 'max_depth': 3, 'learning_rate': 0.021061936086988687, 'subsample': 0.9507298626114318, 'colsample_bytree': 0.5468575199912336, 'min_child_weight': 2, 'reg_alpha': 6.9330260834766655, 'reg_lambda': 6.218606556318885}. Best is trial 25 with value: 0.7606075771753579.\n",
      "[I 2025-10-26 22:58:50,893] Trial 28 finished with value: 0.7613249674693743 and parameters: {'n_estimators': 522, 'max_depth': 3, 'learning_rate': 0.020063643564486953, 'subsample': 0.9526378141083439, 'colsample_bytree': 0.5995197069981046, 'min_child_weight': 2, 'reg_alpha': 7.041075892425384, 'reg_lambda': 6.008982749316686}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:58:52,898] Trial 29 finished with value: 0.744083032325987 and parameters: {'n_estimators': 488, 'max_depth': 3, 'learning_rate': 0.07596337930786534, 'subsample': 0.8290055776807225, 'colsample_bytree': 0.7865242716165667, 'min_child_weight': 2, 'reg_alpha': 9.759734091986228, 'reg_lambda': 4.5121169584587895}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:58:55,096] Trial 30 finished with value: 0.7580909169300302 and parameters: {'n_estimators': 640, 'max_depth': 3, 'learning_rate': 0.02035257055018242, 'subsample': 0.944414464865531, 'colsample_bytree': 0.607999791545776, 'min_child_weight': 1, 'reg_alpha': 7.058236189308873, 'reg_lambda': 6.176423223893251}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:58:57,295] Trial 31 finished with value: 0.7599275748157766 and parameters: {'n_estimators': 651, 'max_depth': 3, 'learning_rate': 0.02075096692447562, 'subsample': 0.9475729414560478, 'colsample_bytree': 0.6057224448124505, 'min_child_weight': 1, 'reg_alpha': 6.824505025922135, 'reg_lambda': 6.08325303455233}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:58:59,218] Trial 32 finished with value: 0.7582635978746695 and parameters: {'n_estimators': 524, 'max_depth': 3, 'learning_rate': 0.02988379603544825, 'subsample': 0.8871464386053001, 'colsample_bytree': 0.647127165745867, 'min_child_weight': 2, 'reg_alpha': 4.943445138011424, 'reg_lambda': 3.284757219398508}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:01,242] Trial 33 finished with value: 0.7597374452771681 and parameters: {'n_estimators': 542, 'max_depth': 3, 'learning_rate': 0.02046168858351479, 'subsample': 0.9576494699885654, 'colsample_bytree': 0.7094511575185458, 'min_child_weight': 1, 'reg_alpha': 7.047550583236817, 'reg_lambda': 5.643799558095186}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:03,077] Trial 34 finished with value: 0.7580474846365551 and parameters: {'n_estimators': 364, 'max_depth': 3, 'learning_rate': 0.03429516936566512, 'subsample': 0.9615513458130237, 'colsample_bytree': 0.7162039308382424, 'min_child_weight': 1, 'reg_alpha': 6.987148598143356, 'reg_lambda': 5.363504775864085}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:05,035] Trial 35 finished with value: 0.7604696163773319 and parameters: {'n_estimators': 468, 'max_depth': 3, 'learning_rate': 0.020986733724466754, 'subsample': 0.9025753330042479, 'colsample_bytree': 0.7631129509050497, 'min_child_weight': 1, 'reg_alpha': 8.497194838156616, 'reg_lambda': 3.641717006280346}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:11,793] Trial 36 finished with value: 0.7254919906844592 and parameters: {'n_estimators': 243, 'max_depth': 10, 'learning_rate': 0.012841347685399782, 'subsample': 0.8459590279839846, 'colsample_bytree': 0.8396085669006808, 'min_child_weight': 2, 'reg_alpha': 8.968766188575154, 'reg_lambda': 3.8583797915205342}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:14,010] Trial 37 finished with value: 0.7121702988284996 and parameters: {'n_estimators': 408, 'max_depth': 4, 'learning_rate': 0.28955538218262217, 'subsample': 0.5146756807396217, 'colsample_bytree': 0.7575851125360101, 'min_child_weight': 1, 'reg_alpha': 8.06166406182826, 'reg_lambda': 3.3175862119250463}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:21,710] Trial 38 finished with value: 0.7304616158072277 and parameters: {'n_estimators': 445, 'max_depth': 9, 'learning_rate': 0.03059859160103176, 'subsample': 0.8931422745483357, 'colsample_bytree': 0.8342341650657535, 'min_child_weight': 3, 'reg_alpha': 8.963056333506433, 'reg_lambda': 7.652671938880764}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:23,795] Trial 39 finished with value: 0.7359052782320843 and parameters: {'n_estimators': 119, 'max_depth': 7, 'learning_rate': 0.0885554540305195, 'subsample': 0.7847133114216979, 'colsample_bytree': 0.7595547361086963, 'min_child_weight': 5, 'reg_alpha': 7.600545930758473, 'reg_lambda': 4.231619561454757}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:26,758] Trial 40 finished with value: 0.7496124696574153 and parameters: {'n_estimators': 495, 'max_depth': 5, 'learning_rate': 0.01750681970429539, 'subsample': 0.918237741301533, 'colsample_bytree': 0.737640332120016, 'min_child_weight': 2, 'reg_alpha': 8.729822045122422, 'reg_lambda': 2.5268456826218575}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:28,821] Trial 41 finished with value: 0.7608798997735826 and parameters: {'n_estimators': 550, 'max_depth': 3, 'learning_rate': 0.012226621323863476, 'subsample': 0.9686646625609616, 'colsample_bytree': 0.7052159467380956, 'min_child_weight': 1, 'reg_alpha': 7.419984679551078, 'reg_lambda': 5.335037003102069}. Best is trial 28 with value: 0.7613249674693743.\n",
      "[I 2025-10-26 22:59:30,859] Trial 42 finished with value: 0.7616359949000715 and parameters: {'n_estimators': 551, 'max_depth': 3, 'learning_rate': 0.01298332806430836, 'subsample': 0.9728972235376215, 'colsample_bytree': 0.690245503444237, 'min_child_weight': 1, 'reg_alpha': 7.610987926440443, 'reg_lambda': 5.007864712729874}. Best is trial 42 with value: 0.7616359949000715.\n",
      "[I 2025-10-26 22:59:32,726] Trial 43 finished with value: 0.7605230732039078 and parameters: {'n_estimators': 465, 'max_depth': 3, 'learning_rate': 0.011892340277650796, 'subsample': 0.9647856947291351, 'colsample_bytree': 0.6919358106872061, 'min_child_weight': 2, 'reg_alpha': 7.522185173889889, 'reg_lambda': 5.3222175804502685}. Best is trial 42 with value: 0.7616359949000715.\n",
      "[I 2025-10-26 22:59:35,025] Trial 44 finished with value: 0.7620422712887731 and parameters: {'n_estimators': 568, 'max_depth': 3, 'learning_rate': 0.01224620525618129, 'subsample': 0.9756033207675527, 'colsample_bytree': 0.7010552741561479, 'min_child_weight': 2, 'reg_alpha': 7.522850432370161, 'reg_lambda': 5.078964076669285}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:37,481] Trial 45 finished with value: 0.7586054058694665 and parameters: {'n_estimators': 551, 'max_depth': 4, 'learning_rate': 0.011868698463192247, 'subsample': 0.9722754832872756, 'colsample_bytree': 0.6476423090530526, 'min_child_weight': 9, 'reg_alpha': 4.648903625139596, 'reg_lambda': 4.961289360142644}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:39,586] Trial 46 finished with value: 0.7607183073941767 and parameters: {'n_estimators': 613, 'max_depth': 3, 'learning_rate': 0.01497008906720568, 'subsample': 0.6440602257306696, 'colsample_bytree': 0.7296323922556176, 'min_child_weight': 3, 'reg_alpha': 7.59669688006996, 'reg_lambda': 6.627187097545894}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:42,259] Trial 47 finished with value: 0.755448264713765 and parameters: {'n_estimators': 603, 'max_depth': 4, 'learning_rate': 0.01541033409724763, 'subsample': 0.6151315723855354, 'colsample_bytree': 0.7286923010999186, 'min_child_weight': 6, 'reg_alpha': 6.355844458853436, 'reg_lambda': 6.356777799327512}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:47,887] Trial 48 finished with value: 0.7408388224122686 and parameters: {'n_estimators': 388, 'max_depth': 8, 'learning_rate': 0.01730400587857247, 'subsample': 0.7377208947942344, 'colsample_bytree': 0.6894526564214515, 'min_child_weight': 3, 'reg_alpha': 7.732572699927626, 'reg_lambda': 5.008563860839881}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:49,422] Trial 49 finished with value: 0.756052243987312 and parameters: {'n_estimators': 274, 'max_depth': 3, 'learning_rate': 0.01126253358986502, 'subsample': 0.7011038098030605, 'colsample_bytree': 0.7792868019264437, 'min_child_weight': 3, 'reg_alpha': 5.403254518237222, 'reg_lambda': 6.697154211215037}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:52,012] Trial 50 finished with value: 0.752216731729617 and parameters: {'n_estimators': 589, 'max_depth': 4, 'learning_rate': 0.015671209573825878, 'subsample': 0.6600915873183854, 'colsample_bytree': 0.8261835367668664, 'min_child_weight': 4, 'reg_alpha': 6.474081414080378, 'reg_lambda': 5.84437171289049}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:54,365] Trial 51 finished with value: 0.7602081414472306 and parameters: {'n_estimators': 722, 'max_depth': 3, 'learning_rate': 0.012098681447410966, 'subsample': 0.9301638624988501, 'colsample_bytree': 0.6502675474914168, 'min_child_weight': 2, 'reg_alpha': 8.321820457597354, 'reg_lambda': 7.537659799773715}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:56,601] Trial 52 finished with value: 0.7608702609719857 and parameters: {'n_estimators': 627, 'max_depth': 3, 'learning_rate': 0.013468489489796478, 'subsample': 0.6187802743045606, 'colsample_bytree': 0.7035556830181139, 'min_child_weight': 2, 'reg_alpha': 9.453313212027043, 'reg_lambda': 7.190106407819366}. Best is trial 44 with value: 0.7620422712887731.\n",
      "[I 2025-10-26 22:59:58,711] Trial 53 finished with value: 0.762607046817318 and parameters: {'n_estimators': 622, 'max_depth': 3, 'learning_rate': 0.010687082041321223, 'subsample': 0.6147406681652494, 'colsample_bytree': 0.7030852543025577, 'min_child_weight': 1, 'reg_alpha': 9.193750516646677, 'reg_lambda': 4.422971569802443}. Best is trial 53 with value: 0.762607046817318.\n",
      "[I 2025-10-26 23:00:01,136] Trial 54 finished with value: 0.7593265879590592 and parameters: {'n_estimators': 550, 'max_depth': 4, 'learning_rate': 0.010361433565161502, 'subsample': 0.5998821049978483, 'colsample_bytree': 0.700974069333303, 'min_child_weight': 1, 'reg_alpha': 9.374433997074275, 'reg_lambda': 4.18439745678059}. Best is trial 53 with value: 0.762607046817318.\n",
      "[I 2025-10-26 23:00:05,421] Trial 55 finished with value: 0.7469743646976736 and parameters: {'n_estimators': 624, 'max_depth': 6, 'learning_rate': 0.01004841628601458, 'subsample': 0.5605229271272041, 'colsample_bytree': 0.670108281956368, 'min_child_weight': 1, 'reg_alpha': 9.226219825513589, 'reg_lambda': 4.982928852875295}. Best is trial 53 with value: 0.762607046817318.\n",
      "[I 2025-10-26 23:00:07,358] Trial 56 finished with value: 0.763693007518713 and parameters: {'n_estimators': 518, 'max_depth': 3, 'learning_rate': 0.013974402854569613, 'subsample': 0.5859306312969063, 'colsample_bytree': 0.6259848616860096, 'min_child_weight': 10, 'reg_alpha': 8.226051949405262, 'reg_lambda': 4.542965489636576}. Best is trial 56 with value: 0.763693007518713.\n",
      "[I 2025-10-26 23:00:09,587] Trial 57 finished with value: 0.7545245781006601 and parameters: {'n_estimators': 502, 'max_depth': 4, 'learning_rate': 0.018023469999332437, 'subsample': 0.5045076333871363, 'colsample_bytree': 0.6239565680442782, 'min_child_weight': 8, 'reg_alpha': 9.991656647177184, 'reg_lambda': 4.227814822153183}. Best is trial 56 with value: 0.763693007518713.\n",
      "[I 2025-10-26 23:00:11,978] Trial 58 finished with value: 0.7597404856375507 and parameters: {'n_estimators': 572, 'max_depth': 4, 'learning_rate': 0.011637174778355736, 'subsample': 0.5781150058558446, 'colsample_bytree': 0.6175921305315506, 'min_child_weight': 10, 'reg_alpha': 8.162753201612881, 'reg_lambda': 4.61633599208212}. Best is trial 56 with value: 0.763693007518713.\n",
      "[I 2025-10-26 23:00:14,747] Trial 59 finished with value: 0.7434388544429158 and parameters: {'n_estimators': 516, 'max_depth': 5, 'learning_rate': 0.04325112505657707, 'subsample': 0.981665765302299, 'colsample_bytree': 0.5895027880003109, 'min_child_weight': 9, 'reg_alpha': 7.837010242750672, 'reg_lambda': 0.15117137090132626}. Best is trial 56 with value: 0.763693007518713.\n",
      "[I 2025-10-26 23:00:16,474] Trial 60 finished with value: 0.7641065455700436 and parameters: {'n_estimators': 414, 'max_depth': 3, 'learning_rate': 0.01375114973332858, 'subsample': 0.5714371616500324, 'colsample_bytree': 0.5807478048094361, 'min_child_weight': 6, 'reg_alpha': 7.399596847116877, 'reg_lambda': 2.840290808315567}. Best is trial 60 with value: 0.7641065455700436.\n",
      "[I 2025-10-26 23:00:18,206] Trial 61 finished with value: 0.7646119025287067 and parameters: {'n_estimators': 434, 'max_depth': 3, 'learning_rate': 0.014471712832017501, 'subsample': 0.5399756270448751, 'colsample_bytree': 0.5218819862803628, 'min_child_weight': 6, 'reg_alpha': 7.247986098245936, 'reg_lambda': 2.5354258595662404}. Best is trial 61 with value: 0.7646119025287067.\n",
      "[I 2025-10-26 23:00:19,824] Trial 62 finished with value: 0.7653156360971761 and parameters: {'n_estimators': 335, 'max_depth': 3, 'learning_rate': 0.014096038619745002, 'subsample': 0.5322798287761916, 'colsample_bytree': 0.576471517754032, 'min_child_weight': 6, 'reg_alpha': 6.391161795669911, 'reg_lambda': 1.3767260916827508}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:21,467] Trial 63 finished with value: 0.7648545030356981 and parameters: {'n_estimators': 333, 'max_depth': 3, 'learning_rate': 0.013589183301889648, 'subsample': 0.5306145311534738, 'colsample_bytree': 0.531402081918431, 'min_child_weight': 6, 'reg_alpha': 6.38263727873814, 'reg_lambda': 1.3357550215011524}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:23,245] Trial 64 finished with value: 0.7633373362219633 and parameters: {'n_estimators': 307, 'max_depth': 4, 'learning_rate': 0.01408371729653435, 'subsample': 0.5353429347381067, 'colsample_bytree': 0.5253272012686154, 'min_child_weight': 6, 'reg_alpha': 5.783694785097129, 'reg_lambda': 1.2596066887132384}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:24,995] Trial 65 finished with value: 0.7632199147647662 and parameters: {'n_estimators': 319, 'max_depth': 4, 'learning_rate': 0.01401756305703712, 'subsample': 0.540744537823307, 'colsample_bytree': 0.521200071790101, 'min_child_weight': 6, 'reg_alpha': 5.813336807217882, 'reg_lambda': 1.3066641437013944}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:27,223] Trial 66 finished with value: 0.7551647527017732 and parameters: {'n_estimators': 358, 'max_depth': 5, 'learning_rate': 0.02308599022418089, 'subsample': 0.5313722862451985, 'colsample_bytree': 0.515894355461647, 'min_child_weight': 6, 'reg_alpha': 5.6571869857662325, 'reg_lambda': 1.2633024940770923}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:28,997] Trial 67 finished with value: 0.7278236456756242 and parameters: {'n_estimators': 303, 'max_depth': 4, 'learning_rate': 0.13023626447314504, 'subsample': 0.5374796866262078, 'colsample_bytree': 0.5331400688786447, 'min_child_weight': 6, 'reg_alpha': 6.403723329234734, 'reg_lambda': 1.3590725897851181}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:30,495] Trial 68 finished with value: 0.7553784432064037 and parameters: {'n_estimators': 199, 'max_depth': 4, 'learning_rate': 0.014633817248131745, 'subsample': 0.5612943007785859, 'colsample_bytree': 0.5728721713990275, 'min_child_weight': 7, 'reg_alpha': 5.341140514771786, 'reg_lambda': 2.3286419772916043}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:32,396] Trial 69 finished with value: 0.7631234962173098 and parameters: {'n_estimators': 325, 'max_depth': 4, 'learning_rate': 0.016362144306359766, 'subsample': 0.5370786659770073, 'colsample_bytree': 0.5194318201435776, 'min_child_weight': 5, 'reg_alpha': 3.486709970835882, 'reg_lambda': 0.8634038170804259}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:33,862] Trial 70 finished with value: 0.7635192807647974 and parameters: {'n_estimators': 206, 'max_depth': 3, 'learning_rate': 0.02279654959961489, 'subsample': 0.5831042647104865, 'colsample_bytree': 0.5527011180655433, 'min_child_weight': 7, 'reg_alpha': 5.867630552288629, 'reg_lambda': 1.9578050258348716}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:35,212] Trial 71 finished with value: 0.7630412869405953 and parameters: {'n_estimators': 201, 'max_depth': 3, 'learning_rate': 0.018481271730123462, 'subsample': 0.5740066421540556, 'colsample_bytree': 0.5456123170944499, 'min_child_weight': 7, 'reg_alpha': 5.9392563776258545, 'reg_lambda': 1.7473082385593348}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:36,715] Trial 72 finished with value: 0.7637024191156037 and parameters: {'n_estimators': 283, 'max_depth': 3, 'learning_rate': 0.014126420479709858, 'subsample': 0.5943679539366136, 'colsample_bytree': 0.5012953399548903, 'min_child_weight': 6, 'reg_alpha': 4.481019535258145, 'reg_lambda': 2.76137886837668}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:38,272] Trial 73 finished with value: 0.7628554902028135 and parameters: {'n_estimators': 275, 'max_depth': 3, 'learning_rate': 0.02315553194266411, 'subsample': 0.5935289087420919, 'colsample_bytree': 0.5692844455765053, 'min_child_weight': 8, 'reg_alpha': 4.367334758066605, 'reg_lambda': 2.7346421672411214}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:39,713] Trial 74 finished with value: 0.7618789823511454 and parameters: {'n_estimators': 223, 'max_depth': 3, 'learning_rate': 0.016286829322780597, 'subsample': 0.5167547614076654, 'colsample_bytree': 0.5020694035555884, 'min_child_weight': 6, 'reg_alpha': 6.644577894561987, 'reg_lambda': 1.9408929800761507}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:41,012] Trial 75 finished with value: 0.7586291662922112 and parameters: {'n_estimators': 151, 'max_depth': 3, 'learning_rate': 0.01899771787775705, 'subsample': 0.5506428018615995, 'colsample_bytree': 0.5379208884638992, 'min_child_weight': 5, 'reg_alpha': 5.305480164481283, 'reg_lambda': 2.7795363822225836}. Best is trial 62 with value: 0.7653156360971761.\n",
      "[I 2025-10-26 23:00:42,740] Trial 76 finished with value: 0.76548562646192 and parameters: {'n_estimators': 408, 'max_depth': 3, 'learning_rate': 0.013847578258415325, 'subsample': 0.5212055688188141, 'colsample_bytree': 0.5553777774884009, 'min_child_weight': 6, 'reg_alpha': 4.946058963950125, 'reg_lambda': 0.5126269318472768}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:44,541] Trial 77 finished with value: 0.7605120505792579 and parameters: {'n_estimators': 426, 'max_depth': 3, 'learning_rate': 0.02728192769517864, 'subsample': 0.5696301689378749, 'colsample_bytree': 0.5598093351001985, 'min_child_weight': 7, 'reg_alpha': 3.9748335748034953, 'reg_lambda': 0.6572911083498694}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:46,196] Trial 78 finished with value: 0.7638261588246715 and parameters: {'n_estimators': 356, 'max_depth': 3, 'learning_rate': 0.017116764185563023, 'subsample': 0.5933968601708431, 'colsample_bytree': 0.5801864280712762, 'min_child_weight': 8, 'reg_alpha': 4.7965583922920585, 'reg_lambda': 1.6385581279258694}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:47,893] Trial 79 finished with value: 0.7496140567595614 and parameters: {'n_estimators': 355, 'max_depth': 3, 'learning_rate': 0.05886801165413254, 'subsample': 0.5191031619443407, 'colsample_bytree': 0.580900568076839, 'min_child_weight': 10, 'reg_alpha': 4.5820397389892085, 'reg_lambda': 0.3516744488080512}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:49,659] Trial 80 finished with value: 0.7646043046734379 and parameters: {'n_estimators': 399, 'max_depth': 3, 'learning_rate': 0.016122417720492933, 'subsample': 0.5011377923039956, 'colsample_bytree': 0.5959021780597801, 'min_child_weight': 8, 'reg_alpha': 4.99002276571402, 'reg_lambda': 1.6173670258229238}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:51,403] Trial 81 finished with value: 0.7652906695031768 and parameters: {'n_estimators': 387, 'max_depth': 3, 'learning_rate': 0.016780678592043335, 'subsample': 0.5040176422856782, 'colsample_bytree': 0.5900995729869946, 'min_child_weight': 8, 'reg_alpha': 5.038531640929774, 'reg_lambda': 1.7200439182005178}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:53,173] Trial 82 finished with value: 0.7646608487487567 and parameters: {'n_estimators': 389, 'max_depth': 3, 'learning_rate': 0.016627050794494776, 'subsample': 0.5042723183225122, 'colsample_bytree': 0.5872675843504238, 'min_child_weight': 8, 'reg_alpha': 5.007089195981856, 'reg_lambda': 1.682214081598908}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:54,857] Trial 83 finished with value: 0.7650262931718135 and parameters: {'n_estimators': 396, 'max_depth': 3, 'learning_rate': 0.016249535369617096, 'subsample': 0.5008400146742379, 'colsample_bytree': 0.5919525590536283, 'min_child_weight': 8, 'reg_alpha': 5.04511539945907, 'reg_lambda': 0.9808958878166056}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:56,544] Trial 84 finished with value: 0.7650055207782595 and parameters: {'n_estimators': 396, 'max_depth': 3, 'learning_rate': 0.016179535179884866, 'subsample': 0.5040310971986258, 'colsample_bytree': 0.5987683269333328, 'min_child_weight': 8, 'reg_alpha': 3.8324337984517047, 'reg_lambda': 0.9410770237719881}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:00:58,264] Trial 85 finished with value: 0.7637281733457806 and parameters: {'n_estimators': 390, 'max_depth': 3, 'learning_rate': 0.019122330741488724, 'subsample': 0.5004192856943714, 'colsample_bytree': 0.5962172854017868, 'min_child_weight': 8, 'reg_alpha': 3.8409155845167344, 'reg_lambda': 0.8511794913423925}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:00,146] Trial 86 finished with value: 0.7631327652358769 and parameters: {'n_estimators': 452, 'max_depth': 3, 'learning_rate': 0.015629756930567007, 'subsample': 0.5236231739430979, 'colsample_bytree': 0.5613057284502136, 'min_child_weight': 9, 'reg_alpha': 3.2022698522479685, 'reg_lambda': 1.0105428706182509}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:01,823] Trial 87 finished with value: 0.7636507165112236 and parameters: {'n_estimators': 384, 'max_depth': 3, 'learning_rate': 0.016855510212207554, 'subsample': 0.5087562161488616, 'colsample_bytree': 0.6085615475158596, 'min_child_weight': 9, 'reg_alpha': 4.1994765935728715, 'reg_lambda': 1.574892411941197}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:03,600] Trial 88 finished with value: 0.7629569413570026 and parameters: {'n_estimators': 437, 'max_depth': 3, 'learning_rate': 0.02163324376855485, 'subsample': 0.5508559162059383, 'colsample_bytree': 0.6378733347429374, 'min_child_weight': 8, 'reg_alpha': 5.094608645934255, 'reg_lambda': 0.408942615705589}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:08,166] Trial 89 finished with value: 0.749382027989053 and parameters: {'n_estimators': 344, 'max_depth': 9, 'learning_rate': 0.019380942783803267, 'subsample': 0.5245684963004238, 'colsample_bytree': 0.5370991219248192, 'min_child_weight': 7, 'reg_alpha': 6.135608952656446, 'reg_lambda': 2.262700946585224}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:10,578] Trial 90 finished with value: 0.7576358570472197 and parameters: {'n_estimators': 476, 'max_depth': 4, 'learning_rate': 0.012980589822295052, 'subsample': 0.5096336391917656, 'colsample_bytree': 0.937113008834873, 'min_child_weight': 9, 'reg_alpha': 4.998530985646217, 'reg_lambda': 0.9913103098560961}. Best is trial 76 with value: 0.76548562646192.\n",
      "[I 2025-10-26 23:01:12,406] Trial 91 finished with value: 0.7657050370316665 and parameters: {'n_estimators': 410, 'max_depth': 3, 'learning_rate': 0.015045552102080887, 'subsample': 0.5494946668756909, 'colsample_bytree': 0.5915983274819723, 'min_child_weight': 7, 'reg_alpha': 6.1774878685238495, 'reg_lambda': 0.008500682384123714}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:14,143] Trial 92 finished with value: 0.7653747056941692 and parameters: {'n_estimators': 402, 'max_depth': 3, 'learning_rate': 0.01520739787936881, 'subsample': 0.5003081512129592, 'colsample_bytree': 0.5939605115838062, 'min_child_weight': 7, 'reg_alpha': 6.225087613394571, 'reg_lambda': 0.20027669209166002}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:15,934] Trial 93 finished with value: 0.7650665185198835 and parameters: {'n_estimators': 419, 'max_depth': 3, 'learning_rate': 0.011154994309482993, 'subsample': 0.5256859011046543, 'colsample_bytree': 0.560584034506971, 'min_child_weight': 7, 'reg_alpha': 6.118754404205173, 'reg_lambda': 0.030477522827257318}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:17,745] Trial 94 finished with value: 0.764000354366936 and parameters: {'n_estimators': 373, 'max_depth': 3, 'learning_rate': 0.011227942450088783, 'subsample': 0.52535798930366, 'colsample_bytree': 0.6152029667006166, 'min_child_weight': 7, 'reg_alpha': 6.137161361317836, 'reg_lambda': 0.46093759226073283}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:19,459] Trial 95 finished with value: 0.764916384828308 and parameters: {'n_estimators': 413, 'max_depth': 3, 'learning_rate': 0.012675539160507402, 'subsample': 0.5493047574441465, 'colsample_bytree': 0.5629520163314403, 'min_child_weight': 7, 'reg_alpha': 5.5374196370740805, 'reg_lambda': 0.02418527457176764}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:21,236] Trial 96 finished with value: 0.7650769309596027 and parameters: {'n_estimators': 410, 'max_depth': 3, 'learning_rate': 0.012615362210815162, 'subsample': 0.551159809056096, 'colsample_bytree': 0.5576043400420992, 'min_child_weight': 7, 'reg_alpha': 5.487629759371028, 'reg_lambda': 0.17222156998483518}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:23,423] Trial 97 finished with value: 0.7620236569148249 and parameters: {'n_estimators': 421, 'max_depth': 4, 'learning_rate': 0.010935012621383392, 'subsample': 0.5499360161309299, 'colsample_bytree': 0.5619383463531775, 'min_child_weight': 7, 'reg_alpha': 5.528233814728888, 'reg_lambda': 0.089084412081324}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:25,238] Trial 98 finished with value: 0.7656826267826576 and parameters: {'n_estimators': 456, 'max_depth': 3, 'learning_rate': 0.01285279887865485, 'subsample': 0.560451880582444, 'colsample_bytree': 0.5479074069602282, 'min_child_weight': 7, 'reg_alpha': 6.672585622589201, 'reg_lambda': 0.05345449025699317}. Best is trial 91 with value: 0.7657050370316665.\n",
      "[I 2025-10-26 23:01:28,318] Trial 99 finished with value: 0.7543229217336928 and parameters: {'n_estimators': 461, 'max_depth': 6, 'learning_rate': 0.015270592958430002, 'subsample': 0.5633782543953209, 'colsample_bytree': 0.5448113400958873, 'min_child_weight': 8, 'reg_alpha': 6.712429489684173, 'reg_lambda': 0.2634318787283627}. Best is trial 91 with value: 0.7657050370316665.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_estimators': 410, 'max_depth': 3, 'learning_rate': 0.015045552102080887, 'subsample': 0.5494946668756909, 'colsample_bytree': 0.5915983274819723, 'min_child_weight': 7, 'reg_alpha': 6.1774878685238495, 'reg_lambda': 0.008500682384123714}\n",
      "Best R2: 0.766\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Giả sử các hàm make_preprocessor, apply_vt_mask, select_topk, X, y, top_idx, top_k đã được định nghĩa\n",
    "\n",
    "def select_topk(X_transformed, top_idx=top_idx):\n",
    "    return X_transformed[:, top_idx] if isinstance(X_transformed, np.ndarray) else X_transformed.iloc[:, top_idx]\n",
    "\n",
    "# Hàm objective cho Optuna\n",
    "def objective(trial):\n",
    "    # Định nghĩa không gian tham số\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'reg_alpha': trial.suggest_float('reg_alpha', 0, 10),\n",
    "        'reg_lambda': trial.suggest_float('reg_lambda', 0, 10),\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'tree_method': 'hist'\n",
    "    }\n",
    "\n",
    "    # Khởi tạo danh sách để lưu RMSE và R2\n",
    "    tscv = TimeSeriesSplit(n_splits=5)\n",
    "    all_rmse, all_r2 = [], []\n",
    "\n",
    "    # Cross-validation\n",
    "    for tr_idx, te_idx in tscv.split(X):\n",
    "        X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "        y_train, y_test = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "        # Preprocessing\n",
    "        preprocessor = make_preprocessor()\n",
    "        preprocessor.fit(X_train, y_train)\n",
    "        X_train_t = select_topk(apply_vt_mask(preprocessor.transform(X_train)), top_idx)\n",
    "        X_test_t = select_topk(apply_vt_mask(preprocessor.transform(X_test)), top_idx)\n",
    "\n",
    "        # Huấn luyện mô hình\n",
    "        model = XGBRegressor(**params)\n",
    "        model.fit(X_train_t, y_train)\n",
    "        y_pred = model.predict(X_test_t)\n",
    "\n",
    "        # Tính toán metrics\n",
    "        rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        all_rmse.append(rmse)\n",
    "        all_r2.append(r2)\n",
    "\n",
    "    # Trả về giá trị trung bình R2 (Optuna tối ưu hóa theo hướng tối đa)\n",
    "    return np.mean(all_r2)\n",
    "\n",
    "# Tạo study và tối ưu hóa\n",
    "study = optuna.create_study(direction='maximize')  # Tối đa hóa R2\n",
    "study.optimize(objective, n_trials=100)  # Thử 50 tổ hợp tham số\n",
    "\n",
    "# Lấy tham số tốt nhất\n",
    "best_params = study.best_params\n",
    "print(\"Best parameters:\", best_params)\n",
    "print(f\"Best R2: {study.best_value:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b8798bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 748, 'max_depth': 3, 'learning_rate': 0.011587939821652413, 'subsample': 0.7734953360178061, 'colsample_bytree': 0.5835833834497329, 'min_child_weight': 9, 'reg_alpha': 1.719826025944296, 'reg_lambda': 5.592049232867018}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7302376f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'n_estimators': 374, 'max_depth': 4, 'learning_rate': 0.012485536016134191, 'subsample': 0.6097062712048895, 'colsample_bytree': 0.6769721953560869, 'min_child_weight': 4, 'reg_alpha': 0.02541725541718065, 'reg_lambda': 2.518986025206981}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "10b6c88b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CV VÒNG 2: Top-54 + Tham số tối ưu ===\n",
      "Fold 1: RMSE=2.586  R2=0.743\n",
      "Fold 2: RMSE=2.485  R2=0.729\n",
      "Fold 3: RMSE=2.312  R2=0.806\n",
      "Fold 4: RMSE=2.557  R2=0.749\n",
      "Fold 5: RMSE=2.176  R2=0.802\n",
      "\n",
      "FINAL: RMSE=2.423 ± 0.156 | R2=0.766\n"
     ]
    }
   ],
   "source": [
    "# ---------- 4) CV vòng 2: REFIT VỚI TOP-K + THAM SỐ TỐI ƯU ----------\n",
    "xgb_final = XGBRegressor(**best_params, random_state=42, n_jobs=-1, tree_method='hist')\n",
    "all_rmse2, all_r2_2 = [], []\n",
    "\n",
    "print(f\"\\n=== CV VÒNG 2: Top-{top_k} + Tham số tối ưu ===\")\n",
    "for fold, (tr_idx, te_idx) in enumerate(tscv.split(X), start=1):\n",
    "    X_train, X_test = X.iloc[tr_idx], X.iloc[te_idx]\n",
    "    y_train, y_test = y.iloc[tr_idx], y.iloc[te_idx]\n",
    "\n",
    "    preprocessor = make_preprocessor()\n",
    "    preprocessor.fit(X_train, y_train)\n",
    "    X_train_t = select_topk(apply_vt_mask(preprocessor.transform(X_train)))\n",
    "    X_test_t  = select_topk(apply_vt_mask(preprocessor.transform(X_test)))\n",
    "\n",
    "    xgb_final.fit(X_train_t, y_train)\n",
    "    y_pred = xgb_final.predict(X_test_t)\n",
    "\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    all_rmse2.append(rmse); all_r2_2.append(r2)\n",
    "    print(f\"Fold {fold}: RMSE={rmse:.3f}  R2={r2:.3f}\")\n",
    "\n",
    "print(f\"\\nFINAL: RMSE={np.mean(all_rmse2):.3f} ± {np.std(all_rmse2):.3f} | R2={np.mean(all_r2_2):.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
